/shared/home/matevz.vidovic/venv/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
Validation phase: False
Namespace(bs=16, nodw=10, sd='test_segnet_pruning_uniform', ptd='./sclera_data', lr=0.001, ips=0, ntibp=10, is_test_run=True, pruning_phase=False, ce_ix=0, ck=3, mti=1000000000.0, map=1000000000.0, nept=1, pbop=False, nftp=1, pnkao=20, rn='flops_num', ptp=0.01, ifn=(0.5, 0.5, 0.5), tp=False, optim='Adam', loss_fn_name='Default', alphas=[])
Device: cuda
path to file: ./sclera_data
summary for train
valid images: 1288
summary for val
valid images: 344
summary for test
valid images: 208
train dataset len: 30
val dataset len: 30
test dataset len: 30
train dataloader num of batches: 2
val dataloader num of batches: 2
test dataloader num of batches: 2
0 trainings have been done without error stopping.
                        Best k models are kept. (possibly (k+1) models are kept if one of the worse models is the last model we have).
                        Enter ts to do a test showcase of the model and re-ask for input.
                        Enter "resource_graph" to trigger resource_graph() and re-ask for input.
                        Enter s to save the model and re-ask for input.
                        Enter g to show the graph of the model and re-ask for input.
                        Enter r to trigger show_results() and re-ask for input.
                        Enter a number to reset in how many trainings we ask you this again, and re-ask for input.
                        Enter p to prune anyways (in production code, that is commented out, so the program will simply stop).
                        Press Enter to continue training.
                        Enter any other key to stop.

                        Enter r to trigger show_results() and re-ask for input.
                        Enter a number to reset in how many trainings we ask you this again, and re-ask for input.
                        Enter p to prune anyways (in production code, that is commented out, so the program will simply stop).
                        Press Enter to continue training.
                        Enter any other key to stop.
/shared/home/matevz.vidovic/venv/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
Validation phase: True
Namespace(bs=48, nodw=48, sd='test_segnet_pruning_uniform', ptd='./vein_sclera_data', lr=0.001, ips=999999, ntibp=1, is_test_run=True, pruning_phase=True, ce_ix=0, ck=3, mti=1000000000.0, map=1, nept=1, pbop=True, nftp=1, pnkao=2, rn='flops_num', ptp=0.0009, ifn=1, tp=True, optim='Adam', loss_fn_name='Default', alphas=[])
Device: cuda
path to file: ./vein_sclera_data
summary for train
valid images: 89
summary for val
valid images: 27
summary for test
valid images: 12
train dataset len: 30
val dataset len: 27
test dataset len: 12
train dataloader num of batches: 1
val dataloader num of batches: 1
test dataloader num of batches: 1
Goal resource value: 40047403755.1104
disallowed_directly: {((0,), 58)}
disallowed_tree_ixs: {((0,), 58)}
----------
sortable_list[:5]: [(((0,), 0), 32, 0.0), (((0,), 0), 31, 0.03125), (((0,), 0), 33, 0.03125), (((0,), 0), 30, 0.0625), (((0,), 0), 34, 0.0625)]
Pruned ((0,), 0), real_kernel_ix: 32, initial_kernel_ix: 32
Pruned ((0,), 2), real_input_slice_ix: 32, initial_input_slice_ix: 32
----------
Pruned ((0,), 1), real kernel ix (in code real_input_slice_ix): 32, initial_input_slice_ix: 32
----------
Current resource value: 40011890688
Copied SegNet_0_after_pruning.pth to ./test_segnet_pruning_uniform/safety_copies/actual_safety_copies
File SegNet_0_after_pruning.pth already exists in safety copies, skipping.
JSON file ./test_segnet_pruning_uniform/safety_copies/safety_copies_0_ending_save.json already exists. We made ./test_segnet_pruning_uniform/safety_copies/safety_copies_0_ending_save_1.json instead.
/shared/home/matevz.vidovic/venv/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/shared/home/matevz.vidovic/Diplomska/Prototip/Delo/ModelWrapper.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model = torch.load(self.prev_model_path, map_location=torch.device(device))
Validation phase: False
Namespace(bs=16, nodw=10, sd='test_segnet_pruning_uniform', ptd='./sclera_data', lr=0.001, ips=0, ntibp=10, is_test_run=True, pruning_phase=False, ce_ix=0, ck=3, mti=1000000000.0, map=1000000000.0, nept=1, pbop=False, nftp=1, pnkao=20, rn='flops_num', ptp=0.01, ifn=(0.5, 0.5, 0.5), tp=False, optim='Adam', loss_fn_name='Default', alphas=[])
Device: cuda
path to file: ./sclera_data
summary for train
valid images: 1288
summary for val
valid images: 344
summary for test
valid images: 208
train dataset len: 30
val dataset len: 30
test dataset len: 30
train dataloader num of batches: 2
val dataloader num of batches: 2
test dataloader num of batches: 2
Loaded model path:  ./test_segnet_pruning_uniform/saved_model_wrapper/SegNet_0_after_pruning.pth
0 trainings have been done without error stopping.
                        Best k models are kept. (possibly (k+1) models are kept if one of the worse models is the last model we have).
                        Enter ts to do a test showcase of the model and re-ask for input.
                        Enter "resource_graph" to trigger resource_graph() and re-ask for input.
                        Enter s to save the model and re-ask for input.
                        Enter g to show the graph of the model and re-ask for input.
                        Enter r to trigger show_results() and re-ask for input.
                        Enter a number to reset in how many trainings we ask you this again, and re-ask for input.
                        Enter p to prune anyways (in production code, that is commented out, so the program will simply stop).
                        Press Enter to continue training.
                        Enter any other key to stop.

                        Enter r to trigger show_results() and re-ask for input.
                        Enter a number to reset in how many trainings we ask you this again, and re-ask for input.
                        Enter p to prune anyways (in production code, that is commented out, so the program will simply stop).
                        Press Enter to continue training.
                        Enter any other key to stop.
File SegNet_0_after_pruning.pth already exists in safety copies, skipping.
JSON file ./test_segnet_pruning_uniform/safety_copies/safety_copies_0_ending_save.json already exists. We made ./test_segnet_pruning_uniform/safety_copies/safety_copies_0_ending_save_1.json instead.
/shared/home/matevz.vidovic/venv/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/shared/home/matevz.vidovic/Diplomska/Prototip/Delo/ModelWrapper.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model = torch.load(self.prev_model_path, map_location=torch.device(device))
Validation phase: True
Namespace(bs=48, nodw=48, sd='test_segnet_pruning_uniform', ptd='./vein_sclera_data', lr=0.001, ips=999999, ntibp=1, is_test_run=True, pruning_phase=True, ce_ix=0, ck=3, mti=1000000000.0, map=1, nept=1, pbop=True, nftp=1, pnkao=2, rn='flops_num', ptp=0.0009, ifn=1, tp=True, optim='Adam', loss_fn_name='Default', alphas=[])
Device: cuda
path to file: ./vein_sclera_data
summary for train
valid images: 89
summary for val
valid images: 27
summary for test
valid images: 12
train dataset len: 30
val dataset len: 27
test dataset len: 12
train dataloader num of batches: 1
val dataloader num of batches: 1
test dataloader num of batches: 1
Loaded model path:  ./test_segnet_pruning_uniform/saved_model_wrapper/SegNet_0_after_pruning.pth
loss: 0.981928  [   30/   30]
validation Error: 
 Avg loss: 0.98342884 
 approx_IoU: 0.008350 
 F1: 0.000328 
 IoU: 0.008350

test Error: 
 Avg loss: 0.98195785 
 approx_IoU: 0.009097 
 F1: 0.000349 
 IoU: 0.009097

File SegNet_0_after_pruning.pth already exists in safety copies, skipping.
Copied SegNet_1_.pth to ./test_segnet_pruning_uniform/safety_copies/actual_safety_copies
Goal resource value: 39975311219.097595
disallowed_directly: {((0,), 0), ((0,), 58), ((0,), 2)}
disallowed_tree_ixs: {((0,), 0), ((0,), 58), ((0,), 2)}
----------
sortable_list[:5]: [(((0,), 5), 64, 2.0), (((0,), 5), 63, 2.015625), (((0,), 5), 65, 2.015625), (((0,), 5), 62, 2.03125), (((0,), 5), 66, 2.03125)]
Pruned ((0,), 5), real_kernel_ix: 64, initial_kernel_ix: 64
Pruned ((0,), 7), real_input_slice_ix: 64, initial_input_slice_ix: 64
----------
Pruned ((0,), 6), real kernel ix (in code real_input_slice_ix): 64, initial_input_slice_ix: 64
----------
Current resource value: 39983579136
disallowed_directly: {((0,), 5), ((0,), 7), ((0,), 0), ((0,), 58), ((0,), 2)}
disallowed_tree_ixs: {((0,), 5), ((0,), 7), ((0,), 0), ((0,), 58), ((0,), 2)}
----------
sortable_list[:5]: [(((0,), 10), 128, 3.0), (((0,), 10), 127, 3.0078125), (((0,), 10), 129, 3.0078125), (((0,), 10), 126, 3.015625), (((0,), 10), 130, 3.015625)]
Pruned ((0,), 10), real_kernel_ix: 128, initial_kernel_ix: 128
Pruned ((0,), 12), real_input_slice_ix: 128, initial_input_slice_ix: 128
----------
Pruned ((0,), 11), real kernel ix (in code real_input_slice_ix): 128, initial_input_slice_ix: 128
----------
Current resource value: 39969423360
File SegNet_0_after_pruning.pth already exists in safety copies, skipping.
File SegNet_1_.pth already exists in safety copies, skipping.
Copied SegNet_1_after_pruning.pth to ./test_segnet_pruning_uniform/safety_copies/actual_safety_copies
File SegNet_0_after_pruning.pth already exists in safety copies, skipping.
File SegNet_1_.pth already exists in safety copies, skipping.
File SegNet_1_after_pruning.pth already exists in safety copies, skipping.
/shared/home/matevz.vidovic/venv/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/shared/home/matevz.vidovic/Diplomska/Prototip/Delo/ModelWrapper.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model = torch.load(self.prev_model_path, map_location=torch.device(device))
Validation phase: False
Namespace(bs=16, nodw=10, sd='test_segnet_pruning_uniform', ptd='./sclera_data', lr=0.001, ips=0, ntibp=10, is_test_run=True, pruning_phase=False, ce_ix=0, ck=3, mti=1000000000.0, map=1000000000.0, nept=1, pbop=False, nftp=1, pnkao=20, rn='flops_num', ptp=0.01, ifn=(0.5, 0.5, 0.5), tp=False, optim='Adam', loss_fn_name='Default', alphas=[])
Device: cuda
path to file: ./sclera_data
summary for train
valid images: 1288
summary for val
valid images: 344
summary for test
valid images: 208
train dataset len: 30
val dataset len: 30
test dataset len: 30
train dataloader num of batches: 2
val dataloader num of batches: 2
test dataloader num of batches: 2
Loaded model path:  ./test_segnet_pruning_uniform/saved_model_wrapper/SegNet_1_after_pruning.pth
0 trainings have been done without error stopping.
                        Best k models are kept. (possibly (k+1) models are kept if one of the worse models is the last model we have).
                        Enter ts to do a test showcase of the model and re-ask for input.
                        Enter "resource_graph" to trigger resource_graph() and re-ask for input.
                        Enter s to save the model and re-ask for input.
                        Enter g to show the graph of the model and re-ask for input.
                        Enter r to trigger show_results() and re-ask for input.
                        Enter a number to reset in how many trainings we ask you this again, and re-ask for input.
                        Enter p to prune anyways (in production code, that is commented out, so the program will simply stop).
                        Press Enter to continue training.
                        Enter any other key to stop.

                        Enter r to trigger show_results() and re-ask for input.
                        Enter a number to reset in how many trainings we ask you this again, and re-ask for input.
                        Enter p to prune anyways (in production code, that is commented out, so the program will simply stop).
                        Press Enter to continue training.
                        Enter any other key to stop.
File SegNet_0_after_pruning.pth already exists in safety copies, skipping.
File SegNet_1_.pth already exists in safety copies, skipping.
File SegNet_1_after_pruning.pth already exists in safety copies, skipping.
JSON file ./test_segnet_pruning_uniform/safety_copies/safety_copies_1_ending_save.json already exists. We made ./test_segnet_pruning_uniform/safety_copies/safety_copies_1_ending_save_1.json instead.
/shared/home/matevz.vidovic/venv/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/shared/home/matevz.vidovic/Diplomska/Prototip/Delo/ModelWrapper.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model = torch.load(self.prev_model_path, map_location=torch.device(device))
Validation phase: True
Namespace(bs=48, nodw=48, sd='test_segnet_pruning_uniform', ptd='./vein_sclera_data', lr=0.001, ips=999999, ntibp=1, is_test_run=True, pruning_phase=True, ce_ix=0, ck=3, mti=1000000000.0, map=1, nept=1, pbop=True, nftp=1, pnkao=2, rn='flops_num', ptp=0.0009, ifn=1, tp=True, optim='Adam', loss_fn_name='Default', alphas=[])
Device: cuda
path to file: ./vein_sclera_data
summary for train
valid images: 89
summary for val
valid images: 27
summary for test
valid images: 12
train dataset len: 30
val dataset len: 27
test dataset len: 12
train dataloader num of batches: 1
val dataloader num of batches: 1
test dataloader num of batches: 1
Loaded model path:  ./test_segnet_pruning_uniform/saved_model_wrapper/SegNet_1_after_pruning.pth
loss: 0.981380  [   30/   30]
validation Error: 
 Avg loss: 0.98300999 
 approx_IoU: 0.008567 
 F1: 0.121262 
 IoU: 0.008570

test Error: 
 Avg loss: 0.98145753 
 approx_IoU: 0.009357 
 F1: 0.124593 
 IoU: 0.009349

File SegNet_0_after_pruning.pth already exists in safety copies, skipping.
File SegNet_1_.pth already exists in safety copies, skipping.
File SegNet_1_after_pruning.pth already exists in safety copies, skipping.
Copied SegNet_2_.pth to ./test_segnet_pruning_uniform/safety_copies/actual_safety_copies
Goal resource value: 39939264951.091194
disallowed_directly: {((0,), 5), ((0,), 7), ((0,), 10), ((0,), 0), ((0,), 58), ((0,), 12), ((0,), 2)}
disallowed_tree_ixs: {((0,), 5), ((0,), 7), ((0,), 10), ((0,), 0), ((0,), 58), ((0,), 12), ((0,), 2)}
----------
sortable_list[:5]: [(((0,), 14), 128, 6.0), (((0,), 14), 127, 6.0078125), (((0,), 14), 129, 6.0078125), (((0,), 14), 126, 6.015625), (((0,), 14), 130, 6.015625)]
Pruned ((0,), 14), real_kernel_ix: 128, initial_kernel_ix: 128
Pruned ((0,), 17), real_input_slice_ix: 128, initial_input_slice_ix: 128
----------
Pruned ((0,), 15), real kernel ix (in code real_input_slice_ix): 128, initial_input_slice_ix: 128
----------
Pruned ((0,), 41), real_kernel_ix: 128, initial_kernel_ix: 128
Pruned ((0,), 44), real_input_slice_ix: 128, initial_input_slice_ix: 128
----------
Pruned ((0,), 42), real kernel ix (in code real_input_slice_ix): 128, initial_input_slice_ix: 128
----------
Current resource value: 39941111808
disallowed_directly: {((0,), 44), ((0,), 5), ((0,), 14), ((0,), 17), ((0,), 7), ((0,), 10), ((0,), 0), ((0,), 58), ((0,), 12), ((0,), 41), ((0,), 2)}
disallowed_tree_ixs: {((0,), 44), ((0,), 5), ((0,), 14), ((0,), 17), ((0,), 7), ((0,), 10), ((0,), 0), ((0,), 58), ((0,), 12), ((0,), 41), ((0,), 2)}
----------
sortable_list[:5]: [(((0,), 19), 256, 7.0), (((0,), 19), 255, 7.00390625), (((0,), 19), 257, 7.00390625), (((0,), 19), 254, 7.0078125), (((0,), 19), 258, 7.0078125)]
Pruned ((0,), 19), real_kernel_ix: 256, initial_kernel_ix: 256
Pruned ((0,), 21), real_input_slice_ix: 256, initial_input_slice_ix: 256
----------
Pruned ((0,), 20), real kernel ix (in code real_input_slice_ix): 256, initial_input_slice_ix: 256
----------
Current resource value: 39931674624
File SegNet_0_after_pruning.pth already exists in safety copies, skipping.
File SegNet_1_.pth already exists in safety copies, skipping.
File SegNet_1_after_pruning.pth already exists in safety copies, skipping.
File SegNet_2_.pth already exists in safety copies, skipping.
Copied SegNet_2_after_pruning.pth to ./test_segnet_pruning_uniform/safety_copies/actual_safety_copies
Deleting model ./test_segnet_pruning_uniform/saved_model_wrapper/SegNet_1_after_pruning.pth
File SegNet_0_after_pruning.pth already exists in safety copies, skipping.
File SegNet_1_.pth already exists in safety copies, skipping.
File SegNet_2_.pth already exists in safety copies, skipping.
File SegNet_2_after_pruning.pth already exists in safety copies, skipping.
/shared/home/matevz.vidovic/venv/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/shared/home/matevz.vidovic/Diplomska/Prototip/Delo/ModelWrapper.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model = torch.load(self.prev_model_path, map_location=torch.device(device))
Validation phase: False
Namespace(bs=16, nodw=10, sd='test_segnet_pruning_uniform', ptd='./sclera_data', lr=0.001, ips=0, ntibp=10, is_test_run=True, pruning_phase=False, ce_ix=0, ck=3, mti=1000000000.0, map=1000000000.0, nept=1, pbop=False, nftp=1, pnkao=20, rn='flops_num', ptp=0.01, ifn=(0.5, 0.5, 0.5), tp=False, optim='Adam', loss_fn_name='Default', alphas=[])
Device: cuda
path to file: ./sclera_data
summary for train
valid images: 1288
summary for val
valid images: 344
summary for test
valid images: 208
train dataset len: 30
val dataset len: 30
test dataset len: 30
train dataloader num of batches: 2
val dataloader num of batches: 2
test dataloader num of batches: 2
Loaded model path:  ./test_segnet_pruning_uniform/saved_model_wrapper/SegNet_2_after_pruning.pth
0 trainings have been done without error stopping.
                        Best k models are kept. (possibly (k+1) models are kept if one of the worse models is the last model we have).
                        Enter ts to do a test showcase of the model and re-ask for input.
                        Enter "resource_graph" to trigger resource_graph() and re-ask for input.
                        Enter s to save the model and re-ask for input.
                        Enter g to show the graph of the model and re-ask for input.
                        Enter r to trigger show_results() and re-ask for input.
                        Enter a number to reset in how many trainings we ask you this again, and re-ask for input.
                        Enter p to prune anyways (in production code, that is commented out, so the program will simply stop).
                        Press Enter to continue training.
                        Enter any other key to stop.

                        Enter r to trigger show_results() and re-ask for input.
                        Enter a number to reset in how many trainings we ask you this again, and re-ask for input.
                        Enter p to prune anyways (in production code, that is commented out, so the program will simply stop).
                        Press Enter to continue training.
                        Enter any other key to stop.
File SegNet_0_after_pruning.pth already exists in safety copies, skipping.
File SegNet_1_.pth already exists in safety copies, skipping.
File SegNet_2_.pth already exists in safety copies, skipping.
File SegNet_2_after_pruning.pth already exists in safety copies, skipping.
JSON file ./test_segnet_pruning_uniform/safety_copies/safety_copies_2_ending_save.json already exists. We made ./test_segnet_pruning_uniform/safety_copies/safety_copies_2_ending_save_1.json instead.
/shared/home/matevz.vidovic/venv/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/shared/home/matevz.vidovic/Diplomska/Prototip/Delo/ModelWrapper.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model = torch.load(self.prev_model_path, map_location=torch.device(device))
Validation phase: True
Namespace(bs=48, nodw=48, sd='test_segnet_pruning_uniform', ptd='./vein_sclera_data', lr=0.001, ips=999999, ntibp=1, is_test_run=True, pruning_phase=True, ce_ix=0, ck=3, mti=1000000000.0, map=1, nept=1, pbop=True, nftp=1, pnkao=2, rn='flops_num', ptp=0.0009, ifn=1, tp=True, optim='Adam', loss_fn_name='Default', alphas=[])
Device: cuda
path to file: ./vein_sclera_data
summary for train
valid images: 89
summary for val
valid images: 27
summary for test
valid images: 12
train dataset len: 30
val dataset len: 27
test dataset len: 12
train dataloader num of batches: 1
val dataloader num of batches: 1
test dataloader num of batches: 1
Loaded model path:  ./test_segnet_pruning_uniform/saved_model_wrapper/SegNet_2_after_pruning.pth
loss: 0.979882  [   30/   30]
validation Error: 
 Avg loss: 0.98343492 
 approx_IoU: 0.008351 
 F1: 0.000906 
 IoU: 0.008352

test Error: 
 Avg loss: 0.98196304 
 approx_IoU: 0.009100 
 F1: 0.000980 
 IoU: 0.009100

Couldn't delete ./test_segnet_pruning_uniform/saved_model_wrapper/SegNet_1_after_pruning.pth. Probably doesn't exist.
File SegNet_0_after_pruning.pth already exists in safety copies, skipping.
File SegNet_1_.pth already exists in safety copies, skipping.
File SegNet_2_.pth already exists in safety copies, skipping.
File SegNet_2_after_pruning.pth already exists in safety copies, skipping.
Copied SegNet_3_.pth to ./test_segnet_pruning_uniform/safety_copies/actual_safety_copies
Goal resource value: 39903218683.08479
disallowed_directly: {((0,), 21), ((0,), 5), ((0,), 44), ((0,), 14), ((0,), 17), ((0,), 7), ((0,), 10), ((0,), 0), ((0,), 58), ((0,), 19), ((0,), 12), ((0,), 41), ((0,), 2)}
disallowed_tree_ixs: {((0,), 21), ((0,), 5), ((0,), 44), ((0,), 14), ((0,), 17), ((0,), 7), ((0,), 10), ((0,), 0), ((0,), 58), ((0,), 19), ((0,), 12), ((0,), 41), ((0,), 2)}
----------
sortable_list[:5]: [(((0,), 24), 256, 10.0), (((0,), 24), 255, 10.00390625), (((0,), 24), 257, 10.00390625), (((0,), 24), 254, 10.0078125), (((0,), 24), 258, 10.0078125)]
Pruned ((0,), 24), real_kernel_ix: 256, initial_kernel_ix: 256
Pruned ((0,), 26), real_input_slice_ix: 256, initial_input_slice_ix: 256
----------
Pruned ((0,), 25), real kernel ix (in code real_input_slice_ix): 256, initial_input_slice_ix: 256
----------
Current resource value: 39929315328
disallowed_directly: {((0,), 21), ((0,), 5), ((0,), 44), ((0,), 24), ((0,), 14), ((0,), 17), ((0,), 7), ((0,), 26), ((0,), 10), ((0,), 0), ((0,), 58), ((0,), 19), ((0,), 12), ((0,), 41), ((0,), 2)}
disallowed_tree_ixs: {((0,), 21), ((0,), 5), ((0,), 44), ((0,), 24), ((0,), 14), ((0,), 17), ((0,), 7), ((0,), 26), ((0,), 10), ((0,), 0), ((0,), 58), ((0,), 19), ((0,), 12), ((0,), 41), ((0,), 2)}
----------
sortable_list[:5]: [(((0,), 28), 256, 11.0), (((0,), 28), 255, 11.00390625), (((0,), 28), 257, 11.00390625), (((0,), 28), 254, 11.0078125), (((0,), 28), 258, 11.0078125)]
Pruned ((0,), 28), real_kernel_ix: 256, initial_kernel_ix: 256
Pruned ((0,), 30), real_input_slice_ix: 256, initial_input_slice_ix: 256
----------
Pruned ((0,), 29), real kernel ix (in code real_input_slice_ix): 256, initial_input_slice_ix: 256
----------
Current resource value: 39926956032
disallowed_directly: {((0,), 21), ((0,), 5), ((0,), 44), ((0,), 24), ((0,), 14), ((0,), 17), ((0,), 7), ((0,), 30), ((0,), 26), ((0,), 10), ((0,), 0), ((0,), 58), ((0,), 19), ((0,), 28), ((0,), 12), ((0,), 41), ((0,), 2)}
disallowed_tree_ixs: {((0,), 21), ((0,), 5), ((0,), 44), ((0,), 24), ((0,), 14), ((0,), 17), ((0,), 7), ((0,), 30), ((0,), 26), ((0,), 10), ((0,), 0), ((0,), 58), ((0,), 19), ((0,), 28), ((0,), 12), ((0,), 41), ((0,), 2)}
----------
sortable_list[:5]: [(((0,), 32), 256, 12.0), (((0,), 32), 255, 12.00390625), (((0,), 32), 257, 12.00390625), (((0,), 32), 254, 12.0078125), (((0,), 32), 258, 12.0078125)]
Pruned ((0,), 32), real_kernel_ix: 256, initial_kernel_ix: 256
Pruned ((0,), 34), real_input_slice_ix: 256, initial_input_slice_ix: 256
----------
Pruned ((0,), 33), real kernel ix (in code real_input_slice_ix): 256, initial_input_slice_ix: 256
----------
Current resource value: 39924596736
disallowed_directly: {((0,), 44), ((0,), 7), ((0,), 10), ((0,), 19), ((0,), 28), ((0,), 34), ((0,), 0), ((0,), 58), ((0,), 12), ((0,), 21), ((0,), 24), ((0,), 30), ((0,), 2), ((0,), 5), ((0,), 14), ((0,), 17), ((0,), 26), ((0,), 32), ((0,), 41)}
disallowed_tree_ixs: {((0,), 44), ((0,), 7), ((0,), 10), ((0,), 19), ((0,), 28), ((0,), 34), ((0,), 0), ((0,), 58), ((0,), 12), ((0,), 21), ((0,), 24), ((0,), 30), ((0,), 2), ((0,), 5), ((0,), 14), ((0,), 17), ((0,), 26), ((0,), 32), ((0,), 41)}
----------
sortable_list[:5]: [(((0,), 37), 256, 13.0), (((0,), 37), 255, 13.00390625), (((0,), 37), 257, 13.00390625), (((0,), 37), 254, 13.0078125), (((0,), 37), 258, 13.0078125)]
Pruned ((0,), 37), real_kernel_ix: 256, initial_kernel_ix: 256
Pruned ((0,), 39), real_input_slice_ix: 256, initial_input_slice_ix: 256
----------
Pruned ((0,), 38), real kernel ix (in code real_input_slice_ix): 256, initial_input_slice_ix: 256
----------
Current resource value: 39915159552
disallowed_directly: {((0,), 44), ((0,), 7), ((0,), 10), ((0,), 19), ((0,), 28), ((0,), 34), ((0,), 37), ((0,), 0), ((0,), 58), ((0,), 12), ((0,), 21), ((0,), 24), ((0,), 30), ((0,), 39), ((0,), 2), ((0,), 5), ((0,), 14), ((0,), 17), ((0,), 26), ((0,), 32), ((0,), 41)}
disallowed_tree_ixs: {((0,), 44), ((0,), 7), ((0,), 10), ((0,), 19), ((0,), 28), ((0,), 34), ((0,), 37), ((0,), 0), ((0,), 58), ((0,), 12), ((0,), 21), ((0,), 24), ((0,), 30), ((0,), 39), ((0,), 2), ((0,), 5), ((0,), 14), ((0,), 17), ((0,), 26), ((0,), 32), ((0,), 41)}
----------
sortable_list[:5]: [(((0,), 46), 128, 16.0), (((0,), 46), 127, 16.0078125), (((0,), 46), 129, 16.0078125), (((0,), 46), 126, 16.015625), (((0,), 46), 130, 16.015625)]
Pruned ((0,), 46), real_kernel_ix: 128, initial_kernel_ix: 128
Pruned ((0,), 48), real_input_slice_ix: 128, initial_input_slice_ix: 128
----------
Pruned ((0,), 47), real kernel ix (in code real_input_slice_ix): 128, initial_input_slice_ix: 128
----------
Current resource value: 39901003776
Deleting model ./test_segnet_pruning_uniform/saved_model_wrapper/SegNet_3_.pth
File SegNet_0_after_pruning.pth already exists in safety copies, skipping.
File SegNet_1_.pth already exists in safety copies, skipping.
File SegNet_2_.pth already exists in safety copies, skipping.
File SegNet_2_after_pruning.pth already exists in safety copies, skipping.
Copied SegNet_3_after_pruning.pth to ./test_segnet_pruning_uniform/safety_copies/actual_safety_copies
Deleting model ./test_segnet_pruning_uniform/saved_model_wrapper/SegNet_3_after_pruning.pth
File SegNet_0_after_pruning.pth already exists in safety copies, skipping.
File SegNet_1_.pth already exists in safety copies, skipping.
File SegNet_2_.pth already exists in safety copies, skipping.
File SegNet_2_after_pruning.pth already exists in safety copies, skipping.
/shared/home/matevz.vidovic/venv/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
Validation phase: False
Namespace(bs=16, nodw=10, sd='test_segnet_pruning_uniform', ptd='./sclera_data', lr=0.001, ips=0, ntibp=10, is_test_run=True, pruning_phase=False, ce_ix=0, ck=3, mti=1000000000.0, map=1000000000.0, nept=1, pbop=False, nftp=1, pnkao=20, rn='flops_num', ptp=0.01, ifn=(0.5, 0.5, 0.5), tp=False, optim='Adam', loss_fn_name='Default', alphas=[])
Device: cuda
path to file: ./sclera_data
summary for train
valid images: 1288
summary for val
valid images: 344
summary for test
valid images: 208
train dataset len: 30
val dataset len: 30
test dataset len: 30
train dataloader num of batches: 2
val dataloader num of batches: 2
test dataloader num of batches: 2
0 trainings have been done without error stopping.
                        Best k models are kept. (possibly (k+1) models are kept if one of the worse models is the last model we have).
                        Enter ts to do a test showcase of the model and re-ask for input.
                        Enter "resource_graph" to trigger resource_graph() and re-ask for input.
                        Enter s to save the model and re-ask for input.
                        Enter g to show the graph of the model and re-ask for input.
                        Enter r to trigger show_results() and re-ask for input.
                        Enter a number to reset in how many trainings we ask you this again, and re-ask for input.
                        Enter p to prune anyways (in production code, that is commented out, so the program will simply stop).
                        Press Enter to continue training.
                        Enter any other key to stop.

                        Enter r to trigger show_results() and re-ask for input.
                        Enter a number to reset in how many trainings we ask you this again, and re-ask for input.
                        Enter p to prune anyways (in production code, that is commented out, so the program will simply stop).
                        Press Enter to continue training.
                        Enter any other key to stop.
File SegNet_0_after_pruning.pth already exists in safety copies, skipping.
File SegNet_1_.pth already exists in safety copies, skipping.
File SegNet_2_.pth already exists in safety copies, skipping.
File SegNet_2_after_pruning.pth already exists in safety copies, skipping.
JSON file ./test_segnet_pruning_uniform/safety_copies/safety_copies_3_ending_save.json already exists. We made ./test_segnet_pruning_uniform/safety_copies/safety_copies_3_ending_save_1.json instead.
/shared/home/matevz.vidovic/venv/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
Validation phase: True
Namespace(bs=48, nodw=48, sd='test_segnet_pruning_uniform', ptd='./vein_sclera_data', lr=0.001, ips=999999, ntibp=1, is_test_run=True, pruning_phase=True, ce_ix=0, ck=3, mti=1000000000.0, map=1, nept=1, pbop=True, nftp=1, pnkao=2, rn='flops_num', ptp=0.0009, ifn=1, tp=True, optim='Adam', loss_fn_name='Default', alphas=[])
Device: cuda
path to file: ./vein_sclera_data
summary for train
valid images: 89
summary for val
valid images: 27
summary for test
valid images: 12
train dataset len: 30
val dataset len: 27
test dataset len: 12
train dataloader num of batches: 1
val dataloader num of batches: 1
test dataloader num of batches: 1
srun: Job step aborted: Waiting up to 122 seconds for job step to finish.
slurmstepd: error: *** STEP 12505.0 ON ana CANCELLED AT 2024-12-10T15:29:14 ***
slurmstepd: error: *** JOB 12505 ON ana CANCELLED AT 2024-12-10T15:29:14 ***
