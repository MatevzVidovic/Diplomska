Validation phase: False
Namespace(iter_possible_stop=999999, BATCH_SIZE=4, NUM_OF_DATALOADER_WORKERS=10, NUM_TRAIN_ITERS_BETWEEN_PRUNINGS=1, SAVE_DIR='SegNet', PATH_TO_DATA='./sclera_data', is_test_run=False, pruning_phase=False, pbop=False, e_ix=3, mti=2, map=1000000000.0, nept=1, pnkao=20, nftp=1, rn='flops_num', ptp=0.01)
path to file: ./sclera_data
summary for train
valid images: 1288
summary for val
valid images: 344
summary for test
valid images: 208
train dataset len: 1288
val dataset len: 344
test dataset len: 208
train dataloader num of batches: 322
val dataloader num of batches: 86
test dataloader num of batches: 52
Device: cuda
loss: 0.685145  [    4/ 1288]
loss: 0.680909  [    8/ 1288]
loss: 0.675103  [   12/ 1288]
loss: 0.667310  [   16/ 1288]
loss: 0.673258  [   20/ 1288]
loss: 0.667324  [   24/ 1288]
loss: 0.666766  [   28/ 1288]
loss: 0.661874  [   32/ 1288]
loss: 0.659061  [   36/ 1288]
loss: 0.657828  [   40/ 1288]
loss: 0.649356  [   44/ 1288]
loss: 0.648280  [   48/ 1288]
loss: 0.646191  [   52/ 1288]
loss: 0.642614  [   56/ 1288]
loss: 0.632935  [   60/ 1288]
loss: 0.634883  [   64/ 1288]
loss: 0.633457  [   68/ 1288]
loss: 0.624129  [   72/ 1288]
loss: 0.627912  [   76/ 1288]
loss: 0.628613  [   80/ 1288]
loss: 0.629865  [   84/ 1288]
loss: 0.623865  [   88/ 1288]
loss: 0.620687  [   92/ 1288]
loss: 0.630013  [   96/ 1288]
loss: 0.607375  [  100/ 1288]
loss: 0.616631  [  104/ 1288]
loss: 0.605097  [  108/ 1288]
loss: 0.609259  [  112/ 1288]
loss: 0.598665  [  116/ 1288]
loss: 0.601627  [  120/ 1288]
loss: 0.593609  [  124/ 1288]
loss: 0.601223  [  128/ 1288]
loss: 0.590925  [  132/ 1288]
loss: 0.589833  [  136/ 1288]
loss: 0.592296  [  140/ 1288]
loss: 0.616853  [  144/ 1288]
loss: 0.583374  [  148/ 1288]
loss: 0.588673  [  152/ 1288]
loss: 0.597985  [  156/ 1288]
loss: 0.583619  [  160/ 1288]
loss: 0.583185  [  164/ 1288]
loss: 0.576375  [  168/ 1288]
loss: 0.576639  [  172/ 1288]
loss: 0.558533  [  176/ 1288]
loss: 0.556087  [  180/ 1288]
loss: 0.568849  [  184/ 1288]
loss: 0.567089  [  188/ 1288]
loss: 0.548277  [  192/ 1288]
loss: 0.574396  [  196/ 1288]
loss: 0.569354  [  200/ 1288]
loss: 0.565143  [  204/ 1288]
loss: 0.565431  [  208/ 1288]
loss: 0.580424  [  212/ 1288]
loss: 0.558024  [  216/ 1288]
loss: 0.551176  [  220/ 1288]
loss: 0.586086  [  224/ 1288]
loss: 0.567831  [  228/ 1288]
loss: 0.554845  [  232/ 1288]
loss: 0.541548  [  236/ 1288]
loss: 0.566449  [  240/ 1288]
loss: 0.562137  [  244/ 1288]
loss: 0.530100  [  248/ 1288]
loss: 0.549863  [  252/ 1288]
loss: 0.576720  [  256/ 1288]
loss: 0.573153  [  260/ 1288]
loss: 0.536560  [  264/ 1288]
loss: 0.555985  [  268/ 1288]
loss: 0.547798  [  272/ 1288]
loss: 0.548356  [  276/ 1288]
loss: 0.540563  [  280/ 1288]
loss: 0.554915  [  284/ 1288]
loss: 0.577728  [  288/ 1288]
loss: 0.564052  [  292/ 1288]
loss: 0.545113  [  296/ 1288]
loss: 0.526096  [  300/ 1288]
loss: 0.524150  [  304/ 1288]
loss: 0.542500  [  308/ 1288]
loss: 0.544594  [  312/ 1288]
loss: 0.550231  [  316/ 1288]
loss: 0.556092  [  320/ 1288]
loss: 0.510813  [  324/ 1288]
loss: 0.532455  [  328/ 1288]
loss: 0.549911  [  332/ 1288]
loss: 0.552862  [  336/ 1288]
loss: 0.525712  [  340/ 1288]
loss: 0.538892  [  344/ 1288]
loss: 0.533095  [  348/ 1288]
loss: 0.527995  [  352/ 1288]
loss: 0.562990  [  356/ 1288]
loss: 0.531195  [  360/ 1288]
loss: 0.513309  [  364/ 1288]
loss: 0.533864  [  368/ 1288]
loss: 0.548174  [  372/ 1288]
loss: 0.515588  [  376/ 1288]
loss: 0.559079  [  380/ 1288]
loss: 0.525442  [  384/ 1288]
loss: 0.552750  [  388/ 1288]
loss: 0.509447  [  392/ 1288]
loss: 0.530539  [  396/ 1288]
loss: 0.532310  [  400/ 1288]
loss: 0.504319  [  404/ 1288]
loss: 0.524413  [  408/ 1288]
loss: 0.529778  [  412/ 1288]
loss: 0.521291  [  416/ 1288]
loss: 0.532622  [  420/ 1288]
loss: 0.521965  [  424/ 1288]
loss: 0.517484  [  428/ 1288]
loss: 0.521981  [  432/ 1288]
loss: 0.531695  [  436/ 1288]
loss: 0.537246  [  440/ 1288]
loss: 0.534985  [  444/ 1288]
loss: 0.517711  [  448/ 1288]
loss: 0.494878  [  452/ 1288]
loss: 0.539946  [  456/ 1288]
loss: 0.521219  [  460/ 1288]
loss: 0.492902  [  464/ 1288]
loss: 0.517917  [  468/ 1288]
loss: 0.509062  [  472/ 1288]
loss: 0.520326  [  476/ 1288]
loss: 0.514910  [  480/ 1288]
loss: 0.490786  [  484/ 1288]
loss: 0.520303  [  488/ 1288]
loss: 0.538492  [  492/ 1288]
loss: 0.531113  [  496/ 1288]
loss: 0.501746  [  500/ 1288]
loss: 0.532477  [  504/ 1288]
loss: 0.530794  [  508/ 1288]
loss: 0.526245  [  512/ 1288]
loss: 0.499055  [  516/ 1288]
loss: 0.504374  [  520/ 1288]
loss: 0.508275  [  524/ 1288]
loss: 0.500561  [  528/ 1288]
loss: 0.494083  [  532/ 1288]
loss: 0.475839  [  536/ 1288]
loss: 0.517888  [  540/ 1288]
loss: 0.532348  [  544/ 1288]
loss: 0.497523  [  548/ 1288]
loss: 0.515942  [  552/ 1288]
loss: 0.520498  [  556/ 1288]
loss: 0.528010  [  560/ 1288]
loss: 0.486520  [  564/ 1288]
loss: 0.510891  [  568/ 1288]
loss: 0.485558  [  572/ 1288]
loss: 0.512585  [  576/ 1288]
loss: 0.502724  [  580/ 1288]
loss: 0.497977  [  584/ 1288]
loss: 0.494257  [  588/ 1288]
loss: 0.472328  [  592/ 1288]
loss: 0.513979  [  596/ 1288]
loss: 0.502632  [  600/ 1288]
loss: 0.495682  [  604/ 1288]
loss: 0.545021  [  608/ 1288]
loss: 0.520005  [  612/ 1288]
loss: 0.526080  [  616/ 1288]
loss: 0.483482  [  620/ 1288]
loss: 0.526573  [  624/ 1288]
loss: 0.495577  [  628/ 1288]
loss: 0.473078  [  632/ 1288]
loss: 0.480318  [  636/ 1288]
loss: 0.492248  [  640/ 1288]
loss: 0.481240  [  644/ 1288]
loss: 0.543159  [  648/ 1288]
loss: 0.516280  [  652/ 1288]
loss: 0.479944  [  656/ 1288]
loss: 0.479940  [  660/ 1288]
loss: 0.503696  [  664/ 1288]
loss: 0.517576  [  668/ 1288]
loss: 0.489406  [  672/ 1288]
loss: 0.519328  [  676/ 1288]
loss: 0.520819  [  680/ 1288]
loss: 0.520531  [  684/ 1288]
loss: 0.488839  [  688/ 1288]
loss: 0.514340  [  692/ 1288]
loss: 0.512986  [  696/ 1288]
loss: 0.502676  [  700/ 1288]
loss: 0.484349  [  704/ 1288]
loss: 0.489047  [  708/ 1288]
loss: 0.488158  [  712/ 1288]
loss: 0.477015  [  716/ 1288]
loss: 0.514571  [  720/ 1288]
loss: 0.487933  [  724/ 1288]
loss: 0.484062  [  728/ 1288]
loss: 0.463490  [  732/ 1288]
loss: 0.509436  [  736/ 1288]
loss: 0.493315  [  740/ 1288]
loss: 0.521386  [  744/ 1288]
loss: 0.506642  [  748/ 1288]
loss: 0.509142  [  752/ 1288]
loss: 0.485661  [  756/ 1288]
loss: 0.503850  [  760/ 1288]
loss: 0.504176  [  764/ 1288]
loss: 0.508925  [  768/ 1288]
loss: 0.480319  [  772/ 1288]
loss: 0.468743  [  776/ 1288]
loss: 0.510234  [  780/ 1288]
loss: 0.507343  [  784/ 1288]
loss: 0.495282  [  788/ 1288]
loss: 0.487225  [  792/ 1288]
loss: 0.482796  [  796/ 1288]
loss: 0.483454  [  800/ 1288]
loss: 0.486997  [  804/ 1288]
loss: 0.463652  [  808/ 1288]
loss: 0.495242  [  812/ 1288]
loss: 0.546521  [  816/ 1288]
loss: 0.490400  [  820/ 1288]
loss: 0.478280  [  824/ 1288]
loss: 0.510778  [  828/ 1288]
loss: 0.550406  [  832/ 1288]
loss: 0.515275  [  836/ 1288]
loss: 0.486944  [  840/ 1288]
loss: 0.471692  [  844/ 1288]
loss: 0.455845  [  848/ 1288]
loss: 0.463214  [  852/ 1288]
loss: 0.478154  [  856/ 1288]
loss: 0.483970  [  860/ 1288]
loss: 0.482117  [  864/ 1288]
loss: 0.541283  [  868/ 1288]
loss: 0.500674  [  872/ 1288]
loss: 0.466884  [  876/ 1288]
loss: 0.495875  [  880/ 1288]
loss: 0.539061  [  884/ 1288]
loss: 0.488314  [  888/ 1288]
loss: 0.511716  [  892/ 1288]
loss: 0.500347  [  896/ 1288]
loss: 0.459537  [  900/ 1288]
loss: 0.487840  [  904/ 1288]
loss: 0.503130  [  908/ 1288]
loss: 0.485465  [  912/ 1288]
loss: 0.491435  [  916/ 1288]
loss: 0.504706  [  920/ 1288]
loss: 0.456493  [  924/ 1288]
loss: 0.472355  [  928/ 1288]
loss: 0.483959  [  932/ 1288]
loss: 0.477893  [  936/ 1288]
loss: 0.482935  [  940/ 1288]
loss: 0.494851  [  944/ 1288]
loss: 0.492714  [  948/ 1288]
loss: 0.477677  [  952/ 1288]
loss: 0.498774  [  956/ 1288]
loss: 0.467716  [  960/ 1288]
loss: 0.468569  [  964/ 1288]
loss: 0.477174  [  968/ 1288]
loss: 0.454831  [  972/ 1288]
loss: 0.454301  [  976/ 1288]
loss: 0.505609  [  980/ 1288]
loss: 0.510866  [  984/ 1288]
loss: 0.504884  [  988/ 1288]
loss: 0.473661  [  992/ 1288]
loss: 0.494598  [  996/ 1288]
loss: 0.471825  [ 1000/ 1288]
loss: 0.470659  [ 1004/ 1288]
loss: 0.482553  [ 1008/ 1288]
loss: 0.508535  [ 1012/ 1288]
loss: 0.499908  [ 1016/ 1288]
loss: 0.523557  [ 1020/ 1288]
loss: 0.489651  [ 1024/ 1288]
loss: 0.502079  [ 1028/ 1288]
loss: 0.493329  [ 1032/ 1288]
loss: 0.486836  [ 1036/ 1288]
loss: 0.489573  [ 1040/ 1288]
loss: 0.486081  [ 1044/ 1288]
loss: 0.482556  [ 1048/ 1288]
loss: 0.459071  [ 1052/ 1288]
loss: 0.486165  [ 1056/ 1288]
loss: 0.476496  [ 1060/ 1288]
loss: 0.480086  [ 1064/ 1288]
loss: 0.505392  [ 1068/ 1288]
loss: 0.518570  [ 1072/ 1288]
loss: 0.444442  [ 1076/ 1288]
loss: 0.491915  [ 1080/ 1288]
loss: 0.477554  [ 1084/ 1288]
loss: 0.448671  [ 1088/ 1288]
loss: 0.486544  [ 1092/ 1288]
loss: 0.487740  [ 1096/ 1288]
loss: 0.507667  [ 1100/ 1288]
loss: 0.501742  [ 1104/ 1288]
loss: 0.485636  [ 1108/ 1288]
loss: 0.505837  [ 1112/ 1288]
loss: 0.498209  [ 1116/ 1288]
loss: 0.492773  [ 1120/ 1288]
loss: 0.461743  [ 1124/ 1288]
loss: 0.469216  [ 1128/ 1288]
loss: 0.474658  [ 1132/ 1288]
loss: 0.513002  [ 1136/ 1288]
loss: 0.517029  [ 1140/ 1288]
loss: 0.517759  [ 1144/ 1288]
loss: 0.519999  [ 1148/ 1288]
loss: 0.462138  [ 1152/ 1288]
loss: 0.484136  [ 1156/ 1288]
loss: 0.476916  [ 1160/ 1288]
loss: 0.565722  [ 1164/ 1288]
loss: 0.477119  [ 1168/ 1288]
loss: 0.512962  [ 1172/ 1288]
loss: 0.473487  [ 1176/ 1288]
loss: 0.496505  [ 1180/ 1288]
loss: 0.449677  [ 1184/ 1288]
loss: 0.454301  [ 1188/ 1288]
loss: 0.454848  [ 1192/ 1288]
loss: 0.495832  [ 1196/ 1288]
loss: 0.510907  [ 1200/ 1288]
loss: 0.477320  [ 1204/ 1288]
loss: 0.492802  [ 1208/ 1288]
loss: 0.481416  [ 1212/ 1288]
loss: 0.509410  [ 1216/ 1288]
loss: 0.446298  [ 1220/ 1288]
loss: 0.461865  [ 1224/ 1288]
loss: 0.489309  [ 1228/ 1288]
loss: 0.488656  [ 1232/ 1288]
loss: 0.478097  [ 1236/ 1288]
loss: 0.501866  [ 1240/ 1288]
loss: 0.462348  [ 1244/ 1288]
loss: 0.466276  [ 1248/ 1288]
loss: 0.474542  [ 1252/ 1288]
loss: 0.481021  [ 1256/ 1288]
loss: 0.473565  [ 1260/ 1288]
loss: 0.459503  [ 1264/ 1288]
loss: 0.473284  [ 1268/ 1288]
loss: 0.457999  [ 1272/ 1288]
loss: 0.465668  [ 1276/ 1288]
loss: 0.465532  [ 1280/ 1288]
loss: 0.440073  [ 1284/ 1288]
loss: 0.498765  [ 1288/ 1288]
/home/matevzvidovic/Desktop/Diplomska/Prototip/Delo/TrainingWrapper.py:225: RuntimeWarning: invalid value encountered in scalar divide
  precision = TP / (TP + FP)
validation Error: 
 Avg loss: 0.47278115 
 IoU: 0.862047 
 F1: nan 

/home/matevzvidovic/Desktop/Diplomska/Prototip/Delo/TrainingWrapper.py:200: RuntimeWarning: invalid value encountered in divide
  IoU = np.diag(confusion_matrix) / (
test Error: 
 Avg loss: 0.46283032 
 IoU: 0.873004 
 F1: nan 

loss: 0.503313  [    4/ 1288]
loss: 0.491610  [    8/ 1288]
loss: 0.498627  [   12/ 1288]
loss: 0.452787  [   16/ 1288]
loss: 0.476390  [   20/ 1288]
loss: 0.470355  [   24/ 1288]
loss: 0.480080  [   28/ 1288]
loss: 0.488958  [   32/ 1288]
loss: 0.466223  [   36/ 1288]
loss: 0.490512  [   40/ 1288]
loss: 0.486388  [   44/ 1288]
loss: 0.461064  [   48/ 1288]
loss: 0.468364  [   52/ 1288]
loss: 0.461074  [   56/ 1288]
loss: 0.483910  [   60/ 1288]
loss: 0.470336  [   64/ 1288]
loss: 0.479353  [   68/ 1288]
loss: 0.427647  [   72/ 1288]
loss: 0.455535  [   76/ 1288]
loss: 0.487316  [   80/ 1288]
loss: 0.504375  [   84/ 1288]
loss: 0.506995  [   88/ 1288]
loss: 0.482182  [   92/ 1288]
loss: 0.453675  [   96/ 1288]
loss: 0.521287  [  100/ 1288]
loss: 0.457758  [  104/ 1288]
loss: 0.476058  [  108/ 1288]
loss: 0.535364  [  112/ 1288]
loss: 0.467063  [  116/ 1288]
loss: 0.445624  [  120/ 1288]
loss: 0.479167  [  124/ 1288]
loss: 0.454646  [  128/ 1288]
loss: 0.497218  [  132/ 1288]
loss: 0.464326  [  136/ 1288]
loss: 0.486737  [  140/ 1288]
loss: 0.477262  [  144/ 1288]
loss: 0.471855  [  148/ 1288]
loss: 0.492446  [  152/ 1288]
loss: 0.501006  [  156/ 1288]
loss: 0.426942  [  160/ 1288]
loss: 0.499590  [  164/ 1288]
loss: 0.490912  [  168/ 1288]
loss: 0.487464  [  172/ 1288]
loss: 0.458504  [  176/ 1288]
loss: 0.504790  [  180/ 1288]
loss: 0.506878  [  184/ 1288]
loss: 0.493840  [  188/ 1288]
loss: 0.486143  [  192/ 1288]
loss: 0.480836  [  196/ 1288]
loss: 0.481382  [  200/ 1288]
loss: 0.462234  [  204/ 1288]
loss: 0.495418  [  208/ 1288]
loss: 0.486968  [  212/ 1288]
loss: 0.493632  [  216/ 1288]
loss: 0.450677  [  220/ 1288]
loss: 0.478120  [  224/ 1288]
loss: 0.515718  [  228/ 1288]
loss: 0.489925  [  232/ 1288]
loss: 0.468046  [  236/ 1288]
loss: 0.465176  [  240/ 1288]
loss: 0.488912  [  244/ 1288]
loss: 0.516171  [  248/ 1288]
loss: 0.493342  [  252/ 1288]
loss: 0.529103  [  256/ 1288]
loss: 0.496759  [  260/ 1288]
loss: 0.452247  [  264/ 1288]
loss: 0.492005  [  268/ 1288]
loss: 0.464808  [  272/ 1288]
loss: 0.457644  [  276/ 1288]
loss: 0.440670  [  280/ 1288]
loss: 0.465512  [  284/ 1288]
loss: 0.480265  [  288/ 1288]
loss: 0.483840  [  292/ 1288]
loss: 0.468917  [  296/ 1288]
loss: 0.446400  [  300/ 1288]
loss: 0.493984  [  304/ 1288]
loss: 0.467605  [  308/ 1288]
loss: 0.471647  [  312/ 1288]
loss: 0.491654  [  316/ 1288]
loss: 0.487204  [  320/ 1288]
loss: 0.491839  [  324/ 1288]
loss: 0.439728  [  328/ 1288]
loss: 0.476714  [  332/ 1288]
loss: 0.479431  [  336/ 1288]
loss: 0.480190  [  340/ 1288]
loss: 0.455447  [  344/ 1288]
loss: 0.481249  [  348/ 1288]
loss: 0.497605  [  352/ 1288]
loss: 0.495242  [  356/ 1288]
loss: 0.488241  [  360/ 1288]
loss: 0.472954  [  364/ 1288]
loss: 0.460421  [  368/ 1288]
loss: 0.482304  [  372/ 1288]
loss: 0.484081  [  376/ 1288]
loss: 0.511658  [  380/ 1288]
loss: 0.479257  [  384/ 1288]
loss: 0.499581  [  388/ 1288]
loss: 0.490772  [  392/ 1288]
loss: 0.457060  [  396/ 1288]
loss: 0.483663  [  400/ 1288]
loss: 0.481651  [  404/ 1288]
loss: 0.483124  [  408/ 1288]
loss: 0.495063  [  412/ 1288]
loss: 0.463645  [  416/ 1288]
loss: 0.463352  [  420/ 1288]
loss: 0.492856  [  424/ 1288]
loss: 0.447478  [  428/ 1288]
loss: 0.467968  [  432/ 1288]
loss: 0.532409  [  436/ 1288]
loss: 0.470879  [  440/ 1288]
loss: 0.512378  [  444/ 1288]
loss: 0.466003  [  448/ 1288]
loss: 0.489417  [  452/ 1288]
loss: 0.409108  [  456/ 1288]
loss: 0.491181  [  460/ 1288]
loss: 0.469032  [  464/ 1288]
loss: 0.471499  [  468/ 1288]
loss: 0.465414  [  472/ 1288]
loss: 0.440198  [  476/ 1288]
loss: 0.508047  [  480/ 1288]
loss: 0.477768  [  484/ 1288]
loss: 0.445648  [  488/ 1288]
loss: 0.422535  [  492/ 1288]
loss: 0.472259  [  496/ 1288]
loss: 0.513189  [  500/ 1288]
loss: 0.451576  [  504/ 1288]
loss: 0.511869  [  508/ 1288]
loss: 0.476979  [  512/ 1288]
loss: 0.445046  [  516/ 1288]
loss: 0.467563  [  520/ 1288]
loss: 0.475068  [  524/ 1288]
loss: 0.492685  [  528/ 1288]
loss: 0.454566  [  532/ 1288]
loss: 0.467818  [  536/ 1288]
loss: 0.455818  [  540/ 1288]
loss: 0.511715  [  544/ 1288]
loss: 0.457244  [  548/ 1288]
loss: 0.498040  [  552/ 1288]
loss: 0.469775  [  556/ 1288]
loss: 0.457895  [  560/ 1288]
loss: 0.455453  [  564/ 1288]
loss: 0.499535  [  568/ 1288]
loss: 0.485465  [  572/ 1288]
loss: 0.496784  [  576/ 1288]
loss: 0.477348  [  580/ 1288]
loss: 0.452230  [  584/ 1288]
loss: 0.508088  [  588/ 1288]
loss: 0.450121  [  592/ 1288]
loss: 0.497009  [  596/ 1288]
loss: 0.448399  [  600/ 1288]
loss: 0.517549  [  604/ 1288]
loss: 0.447217  [  608/ 1288]
loss: 0.465731  [  612/ 1288]
loss: 0.491687  [  616/ 1288]
loss: 0.442297  [  620/ 1288]
loss: 0.474960  [  624/ 1288]
loss: 0.448466  [  628/ 1288]
loss: 0.468292  [  632/ 1288]
loss: 0.452589  [  636/ 1288]
loss: 0.463409  [  640/ 1288]
loss: 0.467204  [  644/ 1288]
loss: 0.490210  [  648/ 1288]
loss: 0.427665  [  652/ 1288]
loss: 0.473676  [  656/ 1288]
loss: 0.465622  [  660/ 1288]
loss: 0.481186  [  664/ 1288]
loss: 0.439188  [  668/ 1288]
loss: 0.468978  [  672/ 1288]
loss: 0.468413  [  676/ 1288]
loss: 0.468178  [  680/ 1288]
loss: 0.504605  [  684/ 1288]
loss: 0.522754  [  688/ 1288]
loss: 0.459965  [  692/ 1288]
loss: 0.459709  [  696/ 1288]
loss: 0.446760  [  700/ 1288]
loss: 0.493863  [  704/ 1288]
loss: 0.472932  [  708/ 1288]
loss: 0.469056  [  712/ 1288]
loss: 0.452437  [  716/ 1288]
loss: 0.446173  [  720/ 1288]
loss: 0.425104  [  724/ 1288]
loss: 0.477867  [  728/ 1288]
loss: 0.418638  [  732/ 1288]
loss: 0.449260  [  736/ 1288]
loss: 0.452248  [  740/ 1288]
loss: 0.457705  [  744/ 1288]
loss: 0.532818  [  748/ 1288]
loss: 0.468511  [  752/ 1288]
loss: 0.448855  [  756/ 1288]
loss: 0.455401  [  760/ 1288]
loss: 0.501769  [  764/ 1288]
loss: 0.463269  [  768/ 1288]
loss: 0.476752  [  772/ 1288]
loss: 0.481499  [  776/ 1288]
loss: 0.481204  [  780/ 1288]
loss: 0.484243  [  784/ 1288]
loss: 0.491158  [  788/ 1288]
loss: 0.458900  [  792/ 1288]
loss: 0.492958  [  796/ 1288]
loss: 0.472134  [  800/ 1288]
loss: 0.432747  [  804/ 1288]
loss: 0.468320  [  808/ 1288]
loss: 0.458278  [  812/ 1288]
loss: 0.472811  [  816/ 1288]
loss: 0.487112  [  820/ 1288]
loss: 0.452574  [  824/ 1288]
loss: 0.462082  [  828/ 1288]
loss: 0.477012  [  832/ 1288]
loss: 0.471938  [  836/ 1288]
loss: 0.456927  [  840/ 1288]
loss: 0.487353  [  844/ 1288]
loss: 0.479798  [  848/ 1288]
loss: 0.470182  [  852/ 1288]
loss: 0.412093  [  856/ 1288]
loss: 0.481073  [  860/ 1288]
loss: 0.481766  [  864/ 1288]
loss: 0.459514  [  868/ 1288]
loss: 0.445646  [  872/ 1288]
loss: 0.485590  [  876/ 1288]
loss: 0.484041  [  880/ 1288]
loss: 0.446286  [  884/ 1288]
loss: 0.438458  [  888/ 1288]
loss: 0.436923  [  892/ 1288]
loss: 0.486924  [  896/ 1288]
loss: 0.470618  [  900/ 1288]
loss: 0.463283  [  904/ 1288]
loss: 0.548499  [  908/ 1288]
loss: 0.467452  [  912/ 1288]
loss: 0.447267  [  916/ 1288]
loss: 0.481088  [  920/ 1288]
loss: 0.471471  [  924/ 1288]
loss: 0.475028  [  928/ 1288]
loss: 0.476121  [  932/ 1288]
loss: 0.450679  [  936/ 1288]
loss: 0.488511  [  940/ 1288]
loss: 0.472410  [  944/ 1288]
loss: 0.458971  [  948/ 1288]
loss: 0.518934  [  952/ 1288]
loss: 0.424238  [  956/ 1288]
loss: 0.488766  [  960/ 1288]
loss: 0.501981  [  964/ 1288]
loss: 0.475914  [  968/ 1288]
loss: 0.476243  [  972/ 1288]
loss: 0.495988  [  976/ 1288]
loss: 0.457378  [  980/ 1288]
loss: 0.469224  [  984/ 1288]
loss: 0.431646  [  988/ 1288]
loss: 0.501414  [  992/ 1288]
loss: 0.443165  [  996/ 1288]
loss: 0.433944  [ 1000/ 1288]
loss: 0.495180  [ 1004/ 1288]
loss: 0.454093  [ 1008/ 1288]
loss: 0.488512  [ 1012/ 1288]
loss: 0.482982  [ 1016/ 1288]
loss: 0.464814  [ 1020/ 1288]
loss: 0.478716  [ 1024/ 1288]
loss: 0.476339  [ 1028/ 1288]
loss: 0.445601  [ 1032/ 1288]
loss: 0.444217  [ 1036/ 1288]
loss: 0.498371  [ 1040/ 1288]
loss: 0.436651  [ 1044/ 1288]
loss: 0.472673  [ 1048/ 1288]
loss: 0.501771  [ 1052/ 1288]
loss: 0.468165  [ 1056/ 1288]
loss: 0.433471  [ 1060/ 1288]
loss: 0.449695  [ 1064/ 1288]
loss: 0.463639  [ 1068/ 1288]
loss: 0.490232  [ 1072/ 1288]
loss: 0.443762  [ 1076/ 1288]
loss: 0.444057  [ 1080/ 1288]
loss: 0.474116  [ 1084/ 1288]
loss: 0.496324  [ 1088/ 1288]
loss: 0.479098  [ 1092/ 1288]
loss: 0.432368  [ 1096/ 1288]
loss: 0.484942  [ 1100/ 1288]
loss: 0.489016  [ 1104/ 1288]
loss: 0.483311  [ 1108/ 1288]
loss: 0.443477  [ 1112/ 1288]
loss: 0.488237  [ 1116/ 1288]
loss: 0.519554  [ 1120/ 1288]
loss: 0.465018  [ 1124/ 1288]
loss: 0.465120  [ 1128/ 1288]
loss: 0.503223  [ 1132/ 1288]
loss: 0.481621  [ 1136/ 1288]
loss: 0.474586  [ 1140/ 1288]
loss: 0.443280  [ 1144/ 1288]
loss: 0.484645  [ 1148/ 1288]
loss: 0.506856  [ 1152/ 1288]
loss: 0.453664  [ 1156/ 1288]
loss: 0.460965  [ 1160/ 1288]
loss: 0.467339  [ 1164/ 1288]
loss: 0.504642  [ 1168/ 1288]
loss: 0.412840  [ 1172/ 1288]
loss: 0.473266  [ 1176/ 1288]
loss: 0.454172  [ 1180/ 1288]
loss: 0.441794  [ 1184/ 1288]
loss: 0.456855  [ 1188/ 1288]
loss: 0.473579  [ 1192/ 1288]
loss: 0.454498  [ 1196/ 1288]
loss: 0.461817  [ 1200/ 1288]
loss: 0.504825  [ 1204/ 1288]
loss: 0.500862  [ 1208/ 1288]
loss: 0.504264  [ 1212/ 1288]
loss: 0.457042  [ 1216/ 1288]
loss: 0.526726  [ 1220/ 1288]
loss: 0.477015  [ 1224/ 1288]
loss: 0.420265  [ 1228/ 1288]
loss: 0.484837  [ 1232/ 1288]
loss: 0.456507  [ 1236/ 1288]
loss: 0.449644  [ 1240/ 1288]
loss: 0.469936  [ 1244/ 1288]
loss: 0.516224  [ 1248/ 1288]
loss: 0.477411  [ 1252/ 1288]
loss: 0.469193  [ 1256/ 1288]
loss: 0.486044  [ 1260/ 1288]
loss: 0.501901  [ 1264/ 1288]
loss: 0.466111  [ 1268/ 1288]
loss: 0.474881  [ 1272/ 1288]
loss: 0.490211  [ 1276/ 1288]
loss: 0.457933  [ 1280/ 1288]
loss: 0.499711  [ 1284/ 1288]
loss: 0.474911  [ 1288/ 1288]
validation Error: 
 Avg loss: 0.46118674 
 IoU: 0.862047 
 F1: nan 

test Error: 
 Avg loss: 0.45068261 
 IoU: 0.873004 
 F1: nan 

