{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_aug_tf.py do_log: False\n",
      "img_augments.py do_log: False\n",
      "helper_img_and_fig_tools.py do_log: False\n",
      "summary for train\n",
      "valid images: 88\n",
      "{'images': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'masks': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'scleras': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'img_names': '10L_l_1'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from dataset_aug_tf import IrisDataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In our UNet implementation the dims can be whatever you want.\n",
    "# You could even change them between training iterations - but it might be a bad idea because all the weights had been learnt at the scale of the previous dims.\n",
    "INPUT_DIMS = {\n",
    "    \"width\" : 256,\n",
    "    \"height\" : 128,\n",
    "    \"channels\" : 5\n",
    "}\n",
    "\n",
    "# In our UNet the output width and height have to be the same as the input width and height. \n",
    "OUTPUT_DIMS = {\n",
    "    \"width\" : INPUT_DIMS[\"width\"],\n",
    "    \"height\" : INPUT_DIMS[\"height\"],\n",
    "    \"channels\" : 2\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model_parameters = {\n",
    "    # layer sizes\n",
    "    \"output_y\" : OUTPUT_DIMS[\"height\"],\n",
    "    \"output_x\" : OUTPUT_DIMS[\"width\"],\n",
    "    \"n_channels\" : INPUT_DIMS[\"channels\"],\n",
    "    \"n_classes\" : OUTPUT_DIMS[\"channels\"],\n",
    "    \"starting_kernels\" : 64,\n",
    "    \"expansion\" : 2,\n",
    "    \"depth\" : 6,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "dataset_args = {\n",
    "\n",
    "    \"testrun\" : True,\n",
    "    \"testrun_size\" : 2,\n",
    "   \n",
    "\n",
    "    \"input_width\" : INPUT_DIMS[\"width\"],\n",
    "    \"input_height\" : INPUT_DIMS[\"height\"],\n",
    "    \"output_width\" : OUTPUT_DIMS[\"width\"],\n",
    "    \"output_height\" : OUTPUT_DIMS[\"height\"],\n",
    "    \n",
    "    # iris dataset params\n",
    "    \"path_to_sclera_data\" : \"Data/vein_and_sclera_data\",\n",
    "    # \"transform\" : transform,\n",
    "    \"n_classes\" : OUTPUT_DIMS[\"channels\"],\n",
    "\n",
    "    \"zero_out_non_sclera\" : True,\n",
    "    \"add_sclera_to_img\" : False,\n",
    "    \"add_bcosfire_to_img\" : True,\n",
    "    \"add_coye_to_img\" : True\n",
    "}\n",
    "\n",
    "\n",
    "data_path = dataset_args[\"path_to_sclera_data\"]\n",
    "# n_classes = 4 if 'sip' in args.dataset.lower() else 2\n",
    "\n",
    "train_dataset = IrisDataset(filepath=data_path, split='train', **dataset_args)\n",
    "\n",
    "\n",
    "real_imgs = train_dataset[0]\n",
    "\n",
    "print(real_imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_img=tensor([[ 1,  2,  3,  4,  5,  6],\n",
      "        [ 7,  8,  9, 10, 11, 12],\n",
      "        [13, 14, 15, 16, 17, 18],\n",
      "        [19, 20, 21, 22, 23, 24]])\n",
      "d3=tensor([[[ 1,  2,  3,  4,  5,  6],\n",
      "         [ 7,  8,  9, 10, 11, 12],\n",
      "         [13, 14, 15, 16, 17, 18]]])\n",
      "patch_indices=[(0, 0), (0, 2), (0, 4), (2, 0), (2, 2), (2, 4)]\n",
      "right_slice=tensor([[ 5,  6],\n",
      "        [11, 12],\n",
      "        [17, 18],\n",
      "        [23, 24]])\n",
      "rs_patches=tensor([[[ 5, 11],\n",
      "         [ 6, 12]],\n",
      "\n",
      "        [[17, 23],\n",
      "         [18, 24]]])\n",
      "rs_ixs=[(0, 4), (2, 4)]\n",
      "bottom_slice=tensor([[13, 14, 15, 16, 17, 18],\n",
      "        [19, 20, 21, 22, 23, 24]])\n",
      "bs_patches=tensor([[[13, 14],\n",
      "         [15, 16],\n",
      "         [17, 18]],\n",
      "\n",
      "        [[19, 20],\n",
      "         [21, 22],\n",
      "         [23, 24]]])\n",
      "bs_ixs=[(2, 0), (2, 1), (2, 2)]\n",
      "right_bottom_corner=tensor([[17, 18],\n",
      "        [23, 24]])\n",
      "rbc_patch=tensor([[[17, 18],\n",
      "         [23, 24]]])\n",
      "rbc_ixs=[(2, 4)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from helper_img_and_fig_tools import smart_conversion, show_image, save_img_quick_figs, save_imgs_quick_figs\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "# from utils import one_hot2dist\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "\n",
    "def get_rising_tensor(shape):\n",
    "\n",
    "    # Calculate the total number of elements needed\n",
    "    num_elements = torch.prod(torch.tensor(shape)).item()\n",
    "\n",
    "    # Create a 1D tensor with sequential numbers\n",
    "    sequential_tensor = torch.arange(1, num_elements + 1)\n",
    "\n",
    "    # Reshape the tensor to the desired shape\n",
    "    reshaped_tensor = sequential_tensor.reshape(shape)\n",
    "\n",
    "    return reshaped_tensor\n",
    "\n",
    "tensor_img_shape = (4, 6)\n",
    "d3_shape = (1, 3, 6)\n",
    "\n",
    "tensor_img = get_rising_tensor(tensor_img_shape)\n",
    "d3 = get_rising_tensor(d3_shape)\n",
    "\n",
    "patch_shape = (2,2)\n",
    "stride = (2,2)\n",
    "\n",
    "print(f\"{tensor_img=}\")\n",
    "print(f\"{d3=}\")\n",
    "\n",
    "tensor_img_unf = tensor_img.unfold(patch_shape[0], stride[0])\n",
    "# print(f\"{tensor_img_unf=}\")\n",
    "# print(f\"{tensor_img_unf.shape=}\")\n",
    "tensor_img_unf = tensor_img_unf.unfold(1, patch_shape[1], stride[1])\n",
    "# print(f\"{tensor_img_unf=}\")\n",
    "# print(f\"{tensor_img_unf.shape=}\")\n",
    "\n",
    "\n",
    "# Calculate the number of patches\n",
    "num_patches_h = (tensor_img.size(0) - patch_shape[0]) // stride[0] + 1\n",
    "num_patches_w = (tensor_img.size(1) - patch_shape[1]) // stride[1] + 1\n",
    "\n",
    "# Calculate starting indices for each patch\n",
    "patch_indices = []\n",
    "for i in range(num_patches_h):\n",
    "    for j in range(num_patches_w):\n",
    "        start_h = i * stride[0]\n",
    "        start_w = j * stride[1]\n",
    "        patch_indices.append((start_h, start_w))\n",
    "\n",
    "print(f\"{patch_indices=}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# right_bottom_patches:\n",
    "\n",
    "# right_patches\n",
    "# bottom_patches\n",
    "# right_bottom_corner\n",
    "\n",
    "# with left up ixs for all of them. And then you concat all of that.\n",
    "# And at test time you add that to that parts of the accumulator.\n",
    "# Possibly you could count how many times each part of the accumulator was added to and devide by that,\n",
    "# but I'm not sure we need that, because it's logits anyway.\n",
    "\n",
    "\n",
    "\n",
    "# right_patches\n",
    "\n",
    "right_slice = tensor_img[:, -patch_shape[1]:]\n",
    "rs_patches = right_slice.unfold(patch_shape[0], stride[0])\n",
    "x_ix = tensor_img.shape[1] - patch_shape[1]\n",
    "rs_ixs = [(i*stride[0], x_ix) for i in range(rs_patches.size(0))]\n",
    "print(f\"{right_slice=}\")\n",
    "print(f\"{rs_patches=}\")\n",
    "print(f\"{rs_ixs=}\")\n",
    "\n",
    "bottom_slice = tensor_img[-patch_shape[0]:, :]\n",
    "bs_patches = bottom_slice.unfold(1, patch_shape[1], stride[1])\n",
    "y_ix = tensor_img.shape[0] - patch_shape[0]\n",
    "bs_ixs = [(y_ix, j) for j in range(bs_patches.size(1))]\n",
    "print(f\"{bottom_slice=}\")\n",
    "print(f\"{bs_patches=}\")\n",
    "print(f\"{bs_ixs=}\")\n",
    "\n",
    "right_bottom_corner = tensor_img[-patch_shape[0]:, -patch_shape[1]:]\n",
    "rbc_patch = right_bottom_corner.reshape(1, *patch_shape)\n",
    "x_ix = tensor_img.shape[1] - patch_shape[1]\n",
    "y_ix = tensor_img.shape[0] - patch_shape[0]\n",
    "rbc_ixs = [(y_ix, x_ix)]\n",
    "print(f\"{right_bottom_corner=}\")\n",
    "print(f\"{rbc_patch=}\")\n",
    "print(f\"{rbc_ixs=}\")\n",
    "\n",
    "\n",
    "# bottom_patches\n",
    "# right_bottom_corner\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def patchify(tensor_imgs_list, patch_shape, stride):\n",
    "    \"\"\"\n",
    "    tensor_imgs_list: list of tensors at the end of __getitem__ function in IrisDataset\n",
    "    patch_shape: tuple of 2 integers (H, W)\n",
    "    stride: tuple of 2 integers (H, W)\n",
    "    \"\"\"\n",
    "    # tensor_imgs_list is a list of tensors\n",
    "    # each tensor is either a 3D tensor of shape (C, H, W)\n",
    "    # or a 2D tensor of shape (H, W) (for grayscale images)\n",
    "    # C is the number of channels\n",
    "    # H is the height of the image\n",
    "    # W is the width of the image\n",
    "\n",
    "    # The function returns a tensor of patches\n",
    "    # of shape (N, C, H, W)\n",
    "    # N is the number of patches\n",
    "\n",
    "    # The function also returns a tensor of patch coordinates (top left and bottom right corners)\n",
    "    # each patch coordinate is a tuple of 4 integers\n",
    "    # an element: (y1, x1, y2, x2)\n",
    "\n",
    "    for tensor_img in tensor_imgs_list:\n",
    "        assert tensor_img.dim() == 3 or tensor_img.dim() == 2\n",
    "        patches = tensor_img.unfold(1, patch_shape[0], stride[0]).unfold(2, patch_shape[1], stride[1])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d3=tensor([[[ 1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8],\n",
      "         [ 9, 10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15, 16],\n",
      "         [17, 18, 19, 20],\n",
      "         [21, 22, 23, 24]]])\n",
      "tensor_img_combined=tensor([[[[ 1,  2],\n",
      "          [ 5,  6]],\n",
      "\n",
      "         [[ 3,  4],\n",
      "          [ 7,  8]]],\n",
      "\n",
      "\n",
      "        [[[13, 14],\n",
      "          [17, 18]],\n",
      "\n",
      "         [[15, 16],\n",
      "          [19, 20]]]])\n",
      "tensor_img_unf=tensor([[[[[ 1,  2],\n",
      "           [ 5,  6]],\n",
      "\n",
      "          [[ 3,  4],\n",
      "           [ 7,  8]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[13, 14],\n",
      "           [17, 18]],\n",
      "\n",
      "          [[15, 16],\n",
      "           [19, 20]]]]])\n",
      "tensor_img_unf.shape=torch.Size([2, 1, 2, 2, 2])\n",
      "patch_indices=[(0, 0)]\n",
      "rs_patches=tensor([[[[ 5, 17],\n",
      "          [ 6, 18],\n",
      "          [ 7, 19],\n",
      "          [ 8, 20]],\n",
      "\n",
      "         [[ 9, 21],\n",
      "          [10, 22],\n",
      "          [11, 23],\n",
      "          [12, 24]]]])\n",
      "rs_ixs=[(0, 1)]\n",
      "bs_patches=tensor([[[[[ 1,  5],\n",
      "           [13, 17]],\n",
      "\n",
      "          [[ 2,  6],\n",
      "           [14, 18]],\n",
      "\n",
      "          [[ 3,  7],\n",
      "           [15, 19]],\n",
      "\n",
      "          [[ 4,  8],\n",
      "           [16, 20]]]]])\n",
      "bs_ixs=[(0, 0)]\n",
      "rbc_patch=tensor([[[ 5,  6,  7,  8],\n",
      "         [ 9, 10, 11, 12]],\n",
      "\n",
      "        [[17, 18, 19, 20],\n",
      "         [21, 22, 23, 24]]])\n",
      "rbc_ixs=[(0, 1)]\n",
      "patch_dict['main_patches'].shape=torch.Size([2, 1, 2, 2, 2])\n",
      "patch_dict['right_patches'].shape=torch.Size([1, 1, 2, 4, 2])\n",
      "patch_dict['bottom_patches'].shape=torch.Size([1, 1, 1, 4, 2, 2])\n",
      "patch_dict['right_bottom_corner'].shape=torch.Size([1, 1, 2, 2, 4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 2 but got size 4 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 210\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatch_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_bottom_corner\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# make tensors have 2 channels as if they went through the model\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m concated_patches \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmain_patches\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mright_patches\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbottom_patches\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mright_bottom_corner\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconcated_patches\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# make tensor 2-channel, by repeating the same data in the second channel. This is for dim=1\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 2 but got size 4 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from helper_img_and_fig_tools import smart_conversion, show_image, save_img_quick_figs, save_imgs_quick_figs\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "# from utils import one_hot2dist\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_rising_tensor(shape):\n",
    "\n",
    "    # Calculate the total number of elements needed\n",
    "    num_elements = torch.prod(torch.tensor(shape)).item()\n",
    "\n",
    "    # Create a 1D tensor with sequential numbers\n",
    "    sequential_tensor = torch.arange(1, num_elements + 1)\n",
    "\n",
    "    # Reshape the tensor to the desired shape\n",
    "    reshaped_tensor = sequential_tensor.reshape(shape)\n",
    "\n",
    "    return reshaped_tensor\n",
    "\n",
    "# tensor_img_shape = (4, 6)\n",
    "d3_shape = (2, 3, 4)\n",
    "\n",
    "# tensor_img = get_rising_tensor(tensor_img_shape)\n",
    "d3 = get_rising_tensor(d3_shape)\n",
    "\n",
    "patch_shape = (2,2)\n",
    "stride = (2,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def unfold_3chan(tensor_img, patch_shape, stride: tuple):\n",
    "    # tensor_img_unf = tensor_img.unfold(0, patch_shape[0], stride[0])\n",
    "    # tensor_img_unf = tensor_img_unf.unfold(1, patch_shape[1], stride[1])\n",
    "\n",
    "    tensor_img_unf = tensor_img.unfold(1, patch_shape[0], stride[0])\n",
    "    tensor_img_unf = tensor_img_unf.unfold(2, patch_shape[1], stride[1])\n",
    "\n",
    "    combined_shape = tensor_img_unf.size(0), -1, patch_shape[0], patch_shape[1]\n",
    "    tensor_img_combined = tensor_img_unf.view(combined_shape)\n",
    "    print(f\"{tensor_img_combined=}\")\n",
    "    \n",
    "    # Calculate the number of patches in each dim\n",
    "    num_patches_h = (tensor_img.size(0) - patch_shape[0]) // stride[0] + 1\n",
    "    num_patches_w = (tensor_img.size(1) - patch_shape[1]) // stride[1] + 1\n",
    "\n",
    "\n",
    "    assert tensor_img_unf.size(1) == num_patches_h * num_patches_w\n",
    "\n",
    "    # Calculate starting indices for each patch\n",
    "    patch_indices = []\n",
    "    for i in range(num_patches_h):\n",
    "        for j in range(num_patches_w):\n",
    "            start_h = i * stride[0]\n",
    "            start_w = j * stride[1]\n",
    "            patch_indices.append((start_h, start_w))\n",
    "            \n",
    "\n",
    "    return tensor_img_unf, patch_indices\n",
    "\n",
    "\n",
    "\n",
    "def patchify(tensor_img, patch_shape, stride: tuple):\n",
    "\n",
    "    # tensor_img_unf = tensor_img.unfold(0, patch_shape[0], stride[0])\n",
    "    # print(f\"{tensor_img_unf=}\")\n",
    "    # print(f\"{tensor_img_unf.shape=}\")\n",
    "    # tensor_img_unf = tensor_img_unf.unfold(1, patch_shape[1], stride[1])\n",
    "    \n",
    "    tensor_img_unf, patch_indices = unfold_3chan(tensor_img, patch_shape, stride)\n",
    "    print(f\"{tensor_img_unf=}\")\n",
    "    print(f\"{tensor_img_unf.shape=}\")\n",
    "    print(f\"{patch_indices=}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # right_bottom_patches:\n",
    "\n",
    "    # right_patches\n",
    "    # bottom_patches\n",
    "    # right_bottom_corner\n",
    "\n",
    "    # with left up ixs for all of them. And then you concat all of that.\n",
    "    # And at test time you add that to that parts of the accumulator.\n",
    "    # Possibly you could count how many times each part of the accumulator was added to and devide by that,\n",
    "    # but I'm not sure we need that, because it's logits anyway.\n",
    "\n",
    "\n",
    "\n",
    "    # right_patches\n",
    "\n",
    "    right_slice = tensor_img[:, -patch_shape[1]:]\n",
    "\n",
    "\n",
    "    rs_patches = right_slice.unfold(0, patch_shape[0], stride[0])\n",
    "    rs_patches.unfold(1, patch_shape[1], stride[1])\n",
    "    x_ix = tensor_img.shape[1] - patch_shape[1]\n",
    "    rs_ixs = [(i*stride[0], x_ix) for i in range(rs_patches.size(0))]\n",
    "    # print(f\"{right_slice=}\")\n",
    "    print(f\"{rs_patches=}\")\n",
    "    print(f\"{rs_ixs=}\")\n",
    "    # make it so the img has the Channel dim, which is 1 in this case\n",
    "    rs_patches = rs_patches.unsqueeze(1)\n",
    "\n",
    "\n",
    "    # bottom_patches\n",
    "\n",
    "    bottom_slice = tensor_img[-patch_shape[0]:, :]\n",
    "    bs_patches = bottom_slice.unfold(0, patch_shape[0], stride[0])\n",
    "    bs_patches = bs_patches.unfold(1, patch_shape[1], stride[1])\n",
    "    y_ix = tensor_img.shape[0] - patch_shape[0]\n",
    "    bs_ixs = [(y_ix, j) for j in range(bs_patches.size(1))]\n",
    "    # print(f\"{bottom_slice=}\")\n",
    "    print(f\"{bs_patches=}\")\n",
    "    print(f\"{bs_ixs=}\")\n",
    "    # make it so the img has the Channel dim, which is 1 in this case\n",
    "    bs_patches = bs_patches.unsqueeze(1)\n",
    "\n",
    "\n",
    "    # right_bottom_corner\n",
    "\n",
    "    right_bottom_corner = tensor_img[-patch_shape[0]:, -patch_shape[1]:]\n",
    "    rbc_patch = right_bottom_corner\n",
    "    x_ix = tensor_img.shape[1] - patch_shape[1]\n",
    "    y_ix = tensor_img.shape[0] - patch_shape[0]\n",
    "    rbc_ixs = [(y_ix, x_ix)]\n",
    "    # print(f\"{right_bottom_corner=}\")\n",
    "    print(f\"{rbc_patch=}\")\n",
    "    print(f\"{rbc_ixs=}\")\n",
    "    # give batch sie and channel dims to this patch\n",
    "    rbc_patch = rbc_patch.unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    \n",
    "    patch_dict = {\n",
    "        \"main_patches\" : tensor_img_unf,\n",
    "        \"main_lu_ixs\" : patch_indices,\n",
    "        \"right_patches\" : rs_patches,\n",
    "        \"right_lu_ixs\" : rs_ixs,\n",
    "        \"bottom_patches\" : bs_patches,\n",
    "        \"bottom_lu_ixs\" : bs_ixs,\n",
    "        \"right_bottom_corner\" : rbc_patch,\n",
    "        \"right_bottom_corner_lu_ixs\" : rbc_ixs\n",
    "    }\n",
    "\n",
    "    return patch_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def accumulate_patches(prediction_tensor_shape, patch_shape, stride: tuple, patch_dict):\n",
    "    \n",
    "    accumulating_tensor = torch.zeros(prediction_tensor_shape)\n",
    "    print(f\"{accumulating_tensor=}\")\n",
    "\n",
    "    for i, (lu_ix, patch) in enumerate(zip(patch_dict[\"main_lu_ixs\"], patch_dict[\"main_patches\"])):\n",
    "\n",
    "        y1, x1 = lu_ix\n",
    "        y2, x2 = y1 + patch_shape[0], x1 + patch_shape[1]\n",
    "        accumulating_tensor[:, y1:y2, x1:x2] += patch\n",
    "    \n",
    "    for i, (lu_ix, patch) in enumerate(zip(patch_dict[\"right_lu_ixs\"], patch_dict[\"right_patches\"])):\n",
    "        \n",
    "        y1, x1 = lu_ix\n",
    "        y2, x2 = y1 + patch_shape[0], x1 + patch_shape[1]\n",
    "        accumulating_tensor[:, y1:y2, x1:x2] += patch\n",
    "\n",
    "    for i, (lu_ix, patch) in enumerate(zip(patch_dict[\"bottom_lu_ixs\"], patch_dict[\"bottom_patches\"])):\n",
    "\n",
    "        y1, x1 = lu_ix\n",
    "        y2, x2 = y1 + patch_shape[0], x1 + patch_shape[1]\n",
    "        accumulating_tensor[:, y1:y2, x1:x2] += patch\n",
    "    \n",
    "    for i, (lu_ix, patch) in enumerate(zip(patch_dict[\"right_bottom_corner_lu_ixs\"], patch_dict[\"right_bottom_corner\"])):\n",
    "        \n",
    "        y1, x1 = lu_ix\n",
    "        y2, x2 = y1 + patch_shape[0], x1 + patch_shape[1]\n",
    "        accumulating_tensor[:, y1:y2, x1:x2] += patch\n",
    "    \n",
    "    return accumulating_tensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"{d3=}\")\n",
    "patch_dict = patchify(d3, patch_shape, stride)\n",
    "\n",
    "# simulate the patches going through the model and becoming 2-channel\n",
    "\n",
    "print(f\"{patch_dict['main_patches'].shape=}\")\n",
    "print(f\"{patch_dict['right_patches'].shape=}\")\n",
    "print(f\"{patch_dict['bottom_patches'].shape=}\")\n",
    "print(f\"{patch_dict['right_bottom_corner'].shape=}\")\n",
    "\n",
    "# make tensors have 2 channels as if they went through the model\n",
    "\n",
    "\n",
    "concated_patches = torch.cat([patch_dict[\"main_patches\"], patch_dict[\"right_patches\"], patch_dict[\"bottom_patches\"], patch_dict[\"right_bottom_corner\"]], dim=0)\n",
    "print(f\"{concated_patches=}\")\n",
    "\n",
    "# make tensor 2-channel, by repeating the same data in the second channel. This is for dim=1\n",
    "concated_patches = concated_patches.repeat(1, 2, 1, 1)\n",
    "print(f\"{concated_patches=}\")\n",
    "\n",
    "# deconcat patches\n",
    "num_main = patch_dict[\"main_patches\"].size(0)\n",
    "num_right = patch_dict[\"right_patches\"].size(0)\n",
    "num_bottom = patch_dict[\"bottom_patches\"].size(0)\n",
    "num_rbc = patch_dict[\"right_bottom_corner\"].size(0)\n",
    "\n",
    "pred_patch_dict = {\n",
    "    \"main_patches\" : concated_patches[:num_main],\n",
    "    \"right_patches\" : concated_patches[num_main:num_main + num_right],\n",
    "    \"bottom_patches\" : concated_patches[num_main + num_right:num_main + num_right + num_bottom],\n",
    "    \"right_bottom_corner\" : concated_patches[num_main + num_right + num_bottom:],\n",
    "\n",
    "    \"main_lu_ixs\" : patch_dict[\"main_lu_ixs\"],\n",
    "    \"right_lu_ixs\" : patch_dict[\"right_lu_ixs\"],\n",
    "    \"bottom_lu_ixs\" : patch_dict[\"bottom_lu_ixs\"],\n",
    "    \"right_bottom_corner_lu_ixs\" : patch_dict[\"right_bottom_corner_lu_ixs\"]\n",
    "}\n",
    "\n",
    "prediction_tensor_shape = (2, tensor_img_shape[0], tensor_img_shape[1])\n",
    "\n",
    "accumulating_tensor = accumulate_patches(prediction_tensor_shape, patch_shape, stride, pred_patch_dict)\n",
    "\n",
    "\n",
    "print(f\"{accumulating_tensor=}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def patchify(tensor_imgs_list, patch_shape, stride):\n",
    "#     \"\"\"\n",
    "#     tensor_imgs_list: list of tensors at the end of __getitem__ function in IrisDataset\n",
    "#     patch_shape: tuple of 2 integers (H, W)\n",
    "#     stride: tuple of 2 integers (H, W)\n",
    "#     \"\"\"\n",
    "#     # tensor_imgs_list is a list of tensors\n",
    "#     # each tensor is either a 3D tensor of shape (C, H, W)\n",
    "#     # or a 2D tensor of shape (H, W) (for grayscale images)\n",
    "#     # C is the number of channels\n",
    "#     # H is the height of the image\n",
    "#     # W is the width of the image\n",
    "\n",
    "#     # The function returns a tensor of patches\n",
    "#     # of shape (N, C, H, W)\n",
    "#     # N is the number of patches\n",
    "\n",
    "#     # The function also returns a tensor of patch coordinates (top left and bottom right corners)\n",
    "#     # each patch coordinate is a tuple of 4 integers\n",
    "#     # an element: (y1, x1, y2, x2)\n",
    "\n",
    "#     for tensor_img in tensor_imgs_list:\n",
    "#         assert tensor_img.dim() == 3 or tensor_img.dim() == 2\n",
    "#         patches = tensor_img.unfold(1, patch_shape[0], stride[0]).unfold(2, patch_shape[1], stride[1])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d3=tensor([[[ 1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8],\n",
      "         [ 9, 10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15, 16],\n",
      "         [17, 18, 19, 20],\n",
      "         [21, 22, 23, 24]]])\n",
      "main_patches=tensor([[[[ 1,  2],\n",
      "          [ 5,  6]],\n",
      "\n",
      "         [[13, 14],\n",
      "          [17, 18]]]])\n",
      "main_patches.shape=torch.Size([1, 2, 2, 2])\n",
      "main_lu_ixs=[(0, 0)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 206\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accumulating_tensor\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md3\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m patch_dict \u001b[38;5;241m=\u001b[39m \u001b[43mpatchify\u001b[49m\u001b[43m(\u001b[49m\u001b[43md3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# The img is 2-channel from the start so the patches are also 2 channel, so they are the same as they would come out of the model\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatch_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain_patches\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 110\u001b[0m, in \u001b[0;36mpatchify\u001b[0;34m(tensor_img, patch_shape, stride)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# right_bottom_patches:\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# right_patches\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# right_patches\u001b[39;00m\n\u001b[1;32m    108\u001b[0m right_slice \u001b[38;5;241m=\u001b[39m tensor_img[:, :, \u001b[38;5;241m-\u001b[39mpatch_shape[\u001b[38;5;241m1\u001b[39m]:]\n\u001b[0;32m--> 110\u001b[0m right_patches, right_lu_ixs \u001b[38;5;241m=\u001b[39m unfold_3chan(right_slice, patch_shape, stride)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mright_slice\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mright_patches\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# Naive patchification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from helper_img_and_fig_tools import smart_conversion, show_image, save_img_quick_figs, save_imgs_quick_figs\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "# from utils import one_hot2dist\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_rising_tensor(shape):\n",
    "\n",
    "    # Calculate the total number of elements needed\n",
    "    num_elements = torch.prod(torch.tensor(shape)).item()\n",
    "\n",
    "    # Create a 1D tensor with sequential numbers\n",
    "    sequential_tensor = torch.arange(1, num_elements + 1)\n",
    "\n",
    "    # Reshape the tensor to the desired shape\n",
    "    reshaped_tensor = sequential_tensor.reshape(shape)\n",
    "\n",
    "    return reshaped_tensor\n",
    "\n",
    "# tensor_img_shape = (4, 6)\n",
    "d3_shape = (2, 3, 4)\n",
    "\n",
    "# tensor_img = get_rising_tensor(tensor_img_shape)\n",
    "d3 = get_rising_tensor(d3_shape)\n",
    "\n",
    "patch_shape = (2,2)\n",
    "stride = (2,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def unfold_3chan(tensor_img, patch_shape, stride: tuple):\n",
    "    # tensor_img_unf = tensor_img.unfold(0, patch_shape[0], stride[0])\n",
    "    # tensor_img_unf = tensor_img_unf.unfold(1, patch_shape[1], stride[1])\n",
    "\n",
    "    y_ix = 0\n",
    "    x_ix = 0\n",
    "\n",
    "    if y_ix + patch_shape[0] < tensor_img.size(1) and x_ix + patch_shape[1] < tensor_img.size(2):\n",
    "        patches = tensor_img[:, y_ix:y_ix + patch_shape[0], x_ix:x_ix + patch_shape[1]]\n",
    "        patches = patches.unsqueeze(0)\n",
    "        left_upper_ixs = [(y_ix, x_ix)]\n",
    "        y_ix += stride[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "    while x_ix + patch_shape[1] < tensor_img.size(2):\n",
    "        while y_ix + patch_shape[0] < tensor_img.size(1):\n",
    "            patch = tensor_img[:, y_ix:y_ix + patch_shape[0], x_ix:x_ix + patch_shape[1]]\n",
    "            patch = patch.unsqueeze(0)\n",
    "            patches = torch.cat([patches, patch], dim=0)\n",
    "            left_upper_ixs.append((y_ix, x_ix))\n",
    "            y_ix += stride[0]\n",
    "        x_ix += stride[1]\n",
    "    \n",
    "    return patches, left_upper_ixs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def patchify(tensor_img, patch_shape, stride: tuple):\n",
    "\n",
    "\n",
    "    main_patches, main_lu_ixs = unfold_3chan(tensor_img, patch_shape, stride)\n",
    "    print(f\"{main_patches=}\")\n",
    "    print(f\"{main_patches.shape=}\")\n",
    "    print(f\"{main_lu_ixs=}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # right_bottom_patches:\n",
    "\n",
    "    # right_patches\n",
    "    # bottom_patches\n",
    "    # right_bottom_corner\n",
    "\n",
    "    # with left up ixs for all of them. And then you concat all of that.\n",
    "    # And at test time you add that to that parts of the accumulator.\n",
    "    # Possibly you could count how many times each part of the accumulator was added to and devide by that,\n",
    "    # but I'm not sure we need that, because it's logits anyway.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # right_patches\n",
    "\n",
    "    right_slice = tensor_img[:, :, -patch_shape[1]:]\n",
    "\n",
    "    right_patches, right_lu_ixs = unfold_3chan(right_slice, patch_shape, stride)\n",
    "\n",
    "    print(f\"{right_slice=}\")\n",
    "    print(f\"{right_patches=}\")\n",
    "    print(f\"{right_patches.shape=}\")\n",
    "    print(f\"{right_lu_ixs=}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # bottom_patches\n",
    "\n",
    "    bottom_slice = tensor_img[:, -patch_shape[0]:, :]\n",
    "    bottom_patches, bottom_lu_ixs = unfold_3chan(bottom_slice, patch_shape, stride)\n",
    "    print(f\"{bottom_slice=}\")\n",
    "    print(f\"{bottom_patches=}\")\n",
    "    print(f\"{bottom_patches.shape=}\")\n",
    "    print(f\"{bottom_lu_ixs=}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # right_bottom_corner\n",
    "\n",
    "    right_bottom_corner = tensor_img[:, -patch_shape[0]:, -patch_shape[1]:]\n",
    "    right_bottom_patches, right_bottom_lu_ixs = unfold_3chan(right_bottom_corner, patch_shape, stride)\n",
    "    print(f\"{right_bottom_corner=}\")\n",
    "    print(f\"{right_bottom_patches=}\")\n",
    "    print(f\"{right_bottom_patches.shape=}\")\n",
    "    print(f\"{right_bottom_lu_ixs=}\")\n",
    "\n",
    "\n",
    "    \n",
    "    # patch_dict = {\n",
    "    #     \"main_patches\" : tensor_img_unf,\n",
    "    #     \"main_lu_ixs\" : patch_indices,\n",
    "    #     \"right_patches\" : rs_patches,\n",
    "    #     \"right_lu_ixs\" : rs_ixs,\n",
    "    #     \"bottom_patches\" : bs_patches,\n",
    "    #     \"bottom_lu_ixs\" : bs_ixs,\n",
    "    #     \"right_bottom_corner\" : rbc_patch,\n",
    "    #     \"right_bottom_corner_lu_ixs\" : rbc_ixs\n",
    "    # }\n",
    "\n",
    "    patch_dict = {\n",
    "        \"main_patches\" : main_patches,\n",
    "        \"main_lu_ixs\" : main_lu_ixs,\n",
    "        \"right_patches\" : right_patches,\n",
    "        \"right_lu_ixs\" : right_lu_ixs,\n",
    "        \"bottom_patches\" : bottom_patches,\n",
    "        \"bottom_lu_ixs\" : bottom_lu_ixs,\n",
    "        \"right_bottom_corner\" : right_bottom_patches,\n",
    "        \"right_bottom_corner_lu_ixs\" : right_bottom_lu_ixs\n",
    "    }\n",
    "\n",
    "    return patch_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def accumulate_patches(prediction_tensor_shape, patch_shape, stride: tuple, patch_dict):\n",
    "    \n",
    "    accumulating_tensor = torch.zeros(prediction_tensor_shape)\n",
    "    print(f\"{accumulating_tensor=}\")\n",
    "\n",
    "    for i, (lu_ix, patch) in enumerate(zip(patch_dict[\"main_lu_ixs\"], patch_dict[\"main_patches\"])):\n",
    "\n",
    "        y1, x1 = lu_ix\n",
    "        y2, x2 = y1 + patch_shape[0], x1 + patch_shape[1]\n",
    "        accumulating_tensor[:, y1:y2, x1:x2] += patch\n",
    "    \n",
    "    for i, (lu_ix, patch) in enumerate(zip(patch_dict[\"right_lu_ixs\"], patch_dict[\"right_patches\"])):\n",
    "        \n",
    "        y1, x1 = lu_ix\n",
    "        y2, x2 = y1 + patch_shape[0], x1 + patch_shape[1]\n",
    "        accumulating_tensor[:, y1:y2, x1:x2] += patch\n",
    "\n",
    "    for i, (lu_ix, patch) in enumerate(zip(patch_dict[\"bottom_lu_ixs\"], patch_dict[\"bottom_patches\"])):\n",
    "\n",
    "        y1, x1 = lu_ix\n",
    "        y2, x2 = y1 + patch_shape[0], x1 + patch_shape[1]\n",
    "        accumulating_tensor[:, y1:y2, x1:x2] += patch\n",
    "    \n",
    "    for i, (lu_ix, patch) in enumerate(zip(patch_dict[\"right_bottom_corner_lu_ixs\"], patch_dict[\"right_bottom_corner\"])):\n",
    "        \n",
    "        y1, x1 = lu_ix\n",
    "        y2, x2 = y1 + patch_shape[0], x1 + patch_shape[1]\n",
    "        accumulating_tensor[:, y1:y2, x1:x2] += patch\n",
    "    \n",
    "    return accumulating_tensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"{d3=}\")\n",
    "patch_dict = patchify(d3, patch_shape, stride)\n",
    "\n",
    "# The img is 2-channel from the start so the patches are also 2 channel, so they are the same as they would come out of the model\n",
    "\n",
    "print(f\"{patch_dict['main_patches'].shape=}\")\n",
    "print(f\"{patch_dict['right_patches'].shape=}\")\n",
    "print(f\"{patch_dict['bottom_patches'].shape=}\")\n",
    "print(f\"{patch_dict['right_bottom_corner'].shape=}\")\n",
    "\n",
    "# make tensors have 2 channels as if they went through the model\n",
    "\n",
    "\n",
    "concated_patches = torch.cat([patch_dict[\"main_patches\"], patch_dict[\"right_patches\"], patch_dict[\"bottom_patches\"], patch_dict[\"right_bottom_corner\"]], dim=0)\n",
    "print(f\"{concated_patches=}\")\n",
    "\n",
    "\n",
    "# deconcat patches\n",
    "num_main = patch_dict[\"main_patches\"].size(0)\n",
    "num_right = patch_dict[\"right_patches\"].size(0)\n",
    "num_bottom = patch_dict[\"bottom_patches\"].size(0)\n",
    "num_rbc = patch_dict[\"right_bottom_corner\"].size(0)\n",
    "\n",
    "pred_patch_dict = {\n",
    "    \"main_patches\" : concated_patches[:num_main],\n",
    "    \"right_patches\" : concated_patches[num_main:num_main + num_right],\n",
    "    \"bottom_patches\" : concated_patches[num_main + num_right:num_main + num_right + num_bottom],\n",
    "    \"right_bottom_corner\" : concated_patches[num_main + num_right + num_bottom:],\n",
    "\n",
    "    \"main_lu_ixs\" : patch_dict[\"main_lu_ixs\"],\n",
    "    \"right_lu_ixs\" : patch_dict[\"right_lu_ixs\"],\n",
    "    \"bottom_lu_ixs\" : patch_dict[\"bottom_lu_ixs\"],\n",
    "    \"right_bottom_corner_lu_ixs\" : patch_dict[\"right_bottom_corner_lu_ixs\"]\n",
    "}\n",
    "\n",
    "prediction_tensor_shape = (2, d3_shape[1], d3_shape[2])\n",
    "\n",
    "accumulating_tensor = accumulate_patches(prediction_tensor_shape, patch_shape, stride, pred_patch_dict)\n",
    "\n",
    "\n",
    "print(f\"{accumulating_tensor=}\")\n",
    "print(f\"{accumulating_tensor.shape=}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
